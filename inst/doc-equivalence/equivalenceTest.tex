% Created 2025-10-21 ti 12:08
% Intended LaTeX compiler: pdflatex
\documentclass[12pt]{article}

%%%% settings when exporting code %%%% 

\usepackage{listings}
\lstdefinestyle{code-small}{
backgroundcolor=\color{white}, % background color for the code block
basicstyle=\ttfamily\small, % font used to display the code
commentstyle=\color[rgb]{0.5,0,0.5}, % color used to display comments in the code
keywordstyle=\color{black}, % color used to highlight certain words in the code
numberstyle=\ttfamily\tiny\color{gray}, % color used to display the line numbers
rulecolor=\color{black}, % color of the frame
stringstyle=\color[rgb]{0,.5,0},  % color used to display strings in the code
breakatwhitespace=false, % sets if automatic breaks should only happen at whitespace
breaklines=true, % sets automatic line breaking
columns=fullflexible,
frame=single, % adds a frame around the code (non,leftline,topline,bottomline,lines,single,shadowbox)
keepspaces=true, % % keeps spaces in text, useful for keeping indentation of code
literate={~}{$\sim$}{1}, % symbol properly display via latex
numbers=none, % where to put the line-numbers; possible values are (none, left, right)
numbersep=10pt, % how far the line-numbers are from the code
showspaces=false,
showstringspaces=false,
stepnumber=1, % the step between two line-numbers. If it's 1, each line will be numbered
tabsize=1,
xleftmargin=0cm,
emph={anova,apply,class,coef,colnames,colNames,colSums,dim,dcast,for,ggplot,head,if,ifelse,is.na,lapply,list.files,library,logLik,melt,plot,require,rowSums,sapply,setcolorder,setkey,str,summary,tapply},
aboveskip = \medskipamount, % define the space above displayed listings.
belowskip = \medskipamount, % define the space above displayed listings.
lineskip = 0pt} % specifies additional space between lines in listings
\lstset{style=code-small}
%%%% packages %%%%%

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage{textcomp}
\usepackage{color}
\usepackage{graphicx}
\usepackage{grffile}
\usepackage{wrapfig}
\usepackage{rotating}
\usepackage{longtable}
\usepackage{multirow}
\usepackage{multicol}
\usepackage{changes}
\usepackage{pdflscape}
\usepackage{geometry}
\usepackage[normalem]{ulem}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{dsfont}
\usepackage{array}
\usepackage{ifthen}
\usepackage{hyperref}
\usepackage{natbib}
\RequirePackage{setspace} % to modify the space between lines - incompatible with footnote in beamer
\renewcommand{\baselinestretch}{1.1}
\geometry{a4paper, left=10mm, right=10mm, top=10mm}
\usepackage{titlesec}
\usepackage{etoolbox}

\makeatletter
\patchcmd{\ttlh@hang}{\parindent\z@}{\parindent\z@\leavevmode}{}{}
\patchcmd{\ttlh@hang}{\noindent}{}{}{}
\makeatother
\RequirePackage{colortbl} % arrayrulecolor to mix colors
\definecolor{myorange}{rgb}{1,0.2,0}
\definecolor{mypurple}{rgb}{0.7,0,8}
\definecolor{mycyan}{rgb}{0,0.6,0.6}
\newcommand{\lightblue}{blue!50!white}
\newcommand{\darkblue}{blue!80!black}
\newcommand{\darkgreen}{green!50!black}
\newcommand{\darkred}{red!50!black}
\definecolor{gray}{gray}{0.5}
\hypersetup{
citecolor=[rgb]{0,0.5,0},
urlcolor=[rgb]{0,0,0.5},
linkcolor=[rgb]{0,0,0.5},
}
\newenvironment{note}{\small \color{gray}\fontfamily{lmtt}\selectfont}{\par}
\newenvironment{activity}{\color{orange}\fontfamily{qzc}\selectfont}{\par}
\RequirePackage{pifont}
\RequirePackage{relsize}
\newcommand{\Cross}{{\raisebox{-0.5ex}%
{\relsize{1.5}\ding{56}}}\hspace{1pt} }
\newcommand{\Valid}{{\raisebox{-0.5ex}%
{\relsize{1.5}\ding{52}}}\hspace{1pt} }
\newcommand{\CrossR}{ \textcolor{red}{\Cross} }
\newcommand{\ValidV}{ \textcolor{green}{\Valid} }
\usepackage{stackengine}
\usepackage{scalerel}
\newcommand\Warning[1][3ex]{%
\renewcommand\stacktype{L}%
\scaleto{\stackon[1.3pt]{\color{red}$\triangle$}{\tiny\bfseries !}}{#1}%
\xspace
}
\RequirePackage{fancyvrb}
\DefineVerbatimEnvironment{verbatim}{Verbatim}{fontsize=\small,formatcom = {\color[rgb]{0.5,0,0}}}
\definecolor{grayR}{HTML}{8A8990}
\definecolor{grayL}{HTML}{C4C7C9}
\definecolor{blueM}{HTML}{1F63B5}
\newcommand{\Rlogo}[1][0.07]{
\begin{tikzpicture}[scale=#1]
\shade [right color=grayR,left color=grayL,shading angle=60]
(-3.55,0.3) .. controls (-3.55,1.75)
and (-1.9,2.7) .. (0,2.7) .. controls (2.05,2.7)
and (3.5,1.6) .. (3.5,0.3) .. controls (3.5,-1.2)
and (1.55,-2) .. (0,-2) .. controls (-2.3,-2)
and (-3.55,-0.75) .. cycle;

\fill[white]
(-2.15,0.2) .. controls (-2.15,1.2)
and (-0.7,1.8) .. (0.5,1.8) .. controls (2.2,1.8)
and (3.1,1.2) .. (3.1,0.2) .. controls (3.1,-0.75)
and (2.4,-1.45) .. (0.5,-1.45) .. controls (-1.1,-1.45)
and (-2.15,-0.7) .. cycle;

\fill[blueM]
(1.75,1.25) -- (-0.65,1.25) -- (-0.65,-2.75) -- (0.55,-2.75) -- (0.55,-1.15) --
(0.95,-1.15)  .. controls (1.15,-1.15)
and (1.5,-1.9) .. (1.9,-2.75) -- (3.25,-2.75)  .. controls (2.2,-1)
and (2.5,-1.2) .. (1.8,-0.95) .. controls (2.6,-0.9)
and (2.85,-0.35) .. (2.85,0.2) .. controls (2.85,0.7)
and (2.5,1.2) .. cycle;

\fill[white]  (1.4,0.4) -- (0.55,0.4) -- (0.55,-0.3) -- (1.4,-0.3).. controls (1.75,-0.3)
and (1.75,0.4) .. cycle;

\end{tikzpicture}
}
\RequirePackage{epstopdf} % to be able to convert .eps to .pdf image files
\RequirePackage{capt-of} %
\RequirePackage{caption} % newlines in graphics
\RequirePackage{tikz-cd} % graph
\RequirePackage{booktabs} % for nice lines in table (e.g. toprule, bottomrule, midrule, cmidrule)
\RequirePackage{amsmath}
\RequirePackage{algorithm}
\RequirePackage[noend]{algpseudocode}
\RequirePackage{dsfont}
\RequirePackage{amsmath,stmaryrd,graphicx}
\RequirePackage{prodint} % product integral symbol (\PRODI)
\usepackage{ifthen}
\usepackage{xifthen}
\usepackage{xargs}
\usepackage{xspace}
\newcommand\defOperator[7]{%
\ifthenelse{\isempty{#2}}{
\ifthenelse{\isempty{#1}}{#7{#3}#4}{#7{#3}#4 \left#5 #1 \right#6}
}{
\ifthenelse{\isempty{#1}}{#7{#3}#4_{#2}}{#7{#3}#4_{#1}\left#5 #2 \right#6}
}
}
\newcommand\defUOperator[5]{%
\ifthenelse{\isempty{#1}}{
#5\left#3 #2 \right#4
}{
\ifthenelse{\isempty{#2}}{\underset{#1}{\operatornamewithlimits{#5}}}{
\underset{#1}{\operatornamewithlimits{#5}}\left#3 #2 \right#4}
}
}
\newcommand{\defBoldVar}[2]{
\ifthenelse{\equal{#2}{T}}{\boldsymbol{#1}}{\mathbf{#1}}
}
\newcommandx\Esp[2][1=,2=]{\defOperator{#1}{#2}{E}{}{\lbrack}{\rbrack}{\mathbb}}
\newcommandx\Prob[2][1=,2=]{\defOperator{#1}{#2}{P}{}{\lbrack}{\rbrack}{\mathbb}}
\newcommandx\Qrob[2][1=,2=]{\defOperator{#1}{#2}{Q}{}{\lbrack}{\rbrack}{\mathbb}}
\newcommandx\Var[2][1=,2=]{\defOperator{#1}{#2}{V}{ar}{\lbrack}{\rbrack}{\mathbb}}
\newcommandx\Cov[2][1=,2=]{\defOperator{#1}{#2}{C}{ov}{\lbrack}{\rbrack}{\mathbb}}
\newcommandx\Binom[2][1=,2=]{\defOperator{#1}{#2}{B}{}{(}{)}{\mathcal}}
\newcommandx\Gaus[2][1=,2=]{\defOperator{#1}{#2}{N}{}{(}{)}{\mathcal}}
\newcommandx\Wishart[2][1=,2=]{\defOperator{#1}{#2}{W}{ishart}{(}{)}{\mathcal}}
\newcommandx\Likelihood[2][1=,2=]{\defOperator{#1}{#2}{L}{}{(}{)}{\mathcal}}
\newcommandx\logLikelihood[2][1=,2=]{\defOperator{#1}{#2}{\ell}{}{(}{)}{}}
\newcommandx\Information[2][1=,2=]{\defOperator{#1}{#2}{I}{}{(}{)}{\mathcal}}
\newcommandx\Hessian[2][1=,2=]{\defOperator{#1}{#2}{H}{}{(}{)}{\mathcal}}
\newcommandx\Score[2][1=,2=]{\defOperator{#1}{#2}{S}{}{(}{)}{\mathcal}}
\newcommandx\Vois[2][1=,2=]{\defOperator{#1}{#2}{V}{}{(}{)}{\mathcal}}
\newcommandx\IF[2][1=,2=]{\defOperator{#1}{#2}{IF}{}{(}{)}{\mathcal}}
\newcommandx\Ind[1][1=]{\defOperator{}{#1}{1}{}{(}{)}{\mathds}}
\newcommandx\Max[2][1=,2=]{\defUOperator{#1}{#2}{(}{)}{min}}
\newcommandx\Min[2][1=,2=]{\defUOperator{#1}{#2}{(}{)}{max}}
\newcommandx\argMax[2][1=,2=]{\defUOperator{#1}{#2}{(}{)}{argmax}}
\newcommandx\argMin[2][1=,2=]{\defUOperator{#1}{#2}{(}{)}{argmin}}
\newcommandx\cvD[2][1=D,2=n \rightarrow \infty]{\xrightarrow[#2]{#1}}
\newcommandx\Hypothesis[2][1=,2=]{
\ifthenelse{\isempty{#1}}{
\mathcal{H}
}{
\ifthenelse{\isempty{#2}}{
\mathcal{H}_{#1}
}{
\mathcal{H}^{(#2)}_{#1}
}
}
}
\newcommandx\dpartial[4][1=,2=,3=,4=\partial]{
\ifthenelse{\isempty{#3}}{
\frac{#4 #1}{#4 #2}
}{
\left.\frac{#4 #1}{#4 #2}\right\rvert_{#3}
}
}
\newcommandx\dTpartial[3][1=,2=,3=]{\dpartial[#1][#2][#3][d]}
\newcommandx\ddpartial[3][1=,2=,3=]{
\ifthenelse{\isempty{#3}}{
\frac{\partial^{2} #1}{\partial #2^2}
}{
\frac{\partial^2 #1}{\partial #2\partial #3}
}
}
\newcommand\Real{\mathbb{R}}
\newcommand\Rational{\mathbb{Q}}
\newcommand\Natural{\mathbb{N}}
\newcommand\trans[1]{{#1}^\intercal}%\newcommand\trans[1]{{\vphantom{#1}}^\top{#1}}
\newcommand{\independent}{\mathrel{\text{\scalebox{1.5}{$\perp\mkern-10mu\perp$}}}}
\newcommand\half{\frac{1}{2}}
\newcommand\normMax[1]{\left|\left|#1\right|\right|_{max}}
\newcommand\normTwo[1]{\left|\left|#1\right|\right|_{2}}
\newcommand\Veta{\boldsymbol{\eta}}
\newcommand{\Model}{\mathcal{M}}
\newcommand{\ModelHat}{\widehat{\mathcal{M}}}
\newcommand{\param}{\Theta}
\newcommand{\paramHat}{\widehat{\param}}
\newcommand{\paramCon}{\widetilde{\param}}
\newcommand{\Vparam}{\boldsymbol{\param}}
\newcommand{\VparamT}{\Vparam_0}
\newcommand{\VparamHat}{\boldsymbol{\paramHat}}
\newcommand{\VparamCon}{\boldsymbol{\paramCon}}
\newcommand{\X}{X}
\newcommand{\x}{x}
\newcommand{\VX}{\boldsymbol{X}}
\newcommand{\Vx}{\boldsymbol{x}}
\newcommand{\Y}{Y}
\newcommand{\y}{y}
\newcommand{\VY}{\boldsymbol{Y}}
\newcommand{\Vy}{\boldsymbol{y}}
\newcommand{\Vvarepsilon}{\boldsymbol{\varepsilon}}
\newcommand{\Z}{Z}
\newcommand{\z}{z}
\newcommand{\VZ}{\boldsymbol{Z}}
\newcommand{\Vz}{\boldsymbol{z}}
\author{Brice Ozenne}
\date{\today}
\title{Connexions between traditional tests and mixed models}
\hypersetup{
 colorlinks=true,
 pdfauthor={Brice Ozenne},
 pdftitle={Connexions between traditional tests and mixed models},
 pdfkeywords={},
 pdfsubject={},
 pdfcreator={Emacs 30.1 (Org mode 9.7.11)},
 pdflang={English}
 }
\begin{document}

\maketitle
This vignette connects well-known tests (t.test, ANCOVA, Pearson's
correlation, Bartlett's test, \ldots) with the output of a linear
mixed model.  .
\section{Illustrative datasets}
\label{sec:org3857166}

We will consider two illustrative datasets:
\begin{itemize}
\item data from the abeta study lifestyle and psychosicial data between
patients with newly diagnosed bipolar disorder (\texttt{BD}) and matched
healthy controls (\texttt{HC}) at baseline: functioning assessment test
(\texttt{fast0}), quality of life (\texttt{qol0}), perceived stress score
(\texttt{pss0}), \ldots{} and at 1 year follow-up (\texttt{pss1}, \texttt{fast1}, \texttt{qol1}, for
\texttt{BD} only).
\end{itemize}
\begin{lstlisting}[language=r,numbers=none]
data(abetaW, package = "LMMstar")
abetaW$missingreason <- NULL
head(abetaW)
\end{lstlisting}

\phantomsection
\label{}
\begin{verbatim}
  id sex age group episode fast0 qol0 pss0 fast1 pss1 qol1 educationyears alcohol
1  1   M  30    BD       0     1   88    9     0   NA   NA             13       0
2  2   F  55    BD       1    32   87   21    NA   NA   NA             15       0
3  3   M  51    BD       0    29   86   23    31   27   79             21       1
4  4   M  38    BD       0     1   96    7     6    6  101             21       1
5  5   M  21    BD       0     3   97    1     1    5  105             12       1
6  6   M  42    BD       1    22   70   17    40   18   68             13       0
\end{verbatim}


This dataset shows great difference in heterogeneity between the two groups, e.g.:
\begin{lstlisting}[language=r,numbers=none]
library(LMMstar)
summarize(pss0 ~ group, data = abetaW, na.rm = TRUE)
\end{lstlisting}

\phantomsection
\label{}
\begin{verbatim}
  group observed missing    mean     sd min   q1 median    q3 max
1    BD       86       1 13.2674 6.8435   1 7.25     13 17.75  29
2    HC       44       0  7.2727 5.0272   0 3.75      6 10.50  19
\end{verbatim}


We will also use a balanced version of this dataset (equal group size):
\begin{lstlisting}[language=r,numbers=none]
abetaW.B <- do.call(rbind, by(abetaW, abetaW$group, function(iDF){
  iDF[which(!is.na(iDF$pss0))[1:44],]
}))
\end{lstlisting}

\clearpage

\begin{itemize}
\item data from the calcium dataset, a two-arm randomized clinical trial
comparing bone mineral density between calcium supplement (\texttt{C}) and
placebo (\texttt{P}). Visits were planned every 6 months, \texttt{bmd1} refers to
the baseline measurement and \texttt{bmd2}, \ldots, \texttt{bmd5} refers to
post-intervention measurements. \texttt{time.obs1},\ldots, \texttt{time.obs5}
refer to the time elpased from baseline measurement in years.
\end{itemize}

\begin{lstlisting}[language=r,numbers=none]
data(calciumL, package = "LMMstar")
calciumL <- merge(by = "girl", calciumL,
                  transform(calciumL, baseline = bmd)[calciumL$visit==1,c("girl","baseline")])
calciumL <- calciumL[order(calciumL$girl,calciumL$visit),]
head(calciumL)
\end{lstlisting}

\phantomsection
\label{}
\begin{verbatim}
   girl grp dropout dropvisit visit time.obs bmd baseline
1   101   C       0        NA     1  0.00000 815      815
3   101   C       0        NA     2  0.51472 875      815
5   101   C       0        NA     3  0.98015 911      815
2   101   C       0        NA     4  1.49760 952      815
4   101   C       0        NA     5  1.99589 970      815
10  102   P       0        NA     1  0.00000 813      813
\end{verbatim}



The corresponding wide format is
\begin{lstlisting}[language=r,numbers=none]
data(calciumW, package = "LMMstar")
calciumW$dropout <- NULL
calciumW$dropvisit <- NULL
head(calciumW)
\end{lstlisting}

\phantomsection
\label{}
\begin{verbatim}
  girl grp bmd1 bmd2 bmd3 bmd4 bmd5 time.obs1 time.obs2 time.obs3 time.obs4 time.obs5
1  101   C  815  875  911  952  970         0   0.51472   0.98015    1.4976    1.9959
2  102   P  813  833  855  881  901         0   0.51472   0.95551    1.4730    1.9521
3  103   P  812  812  843  855  895         0   0.51198   0.95825    1.4757    1.9548
4  104   C  804  847  885  920  948         0   0.51198   0.97194    1.5086    2.1136
5  105   C  904  927  952  955 1002         0   0.57495   0.97741    1.4757    1.9548
6  106   P  831  855  890  908  933         0   0.53388   1.01300    1.5907    2.1684
\end{verbatim}


We will use the placebo group as reference:
\begin{lstlisting}[language=r,numbers=none]
calciumW$grp <- relevel(calciumW$grp, "P")
calciumL$grp <- relevel(calciumL$grp, "P")
\end{lstlisting}

and the change from baseline in bone mineral density:
\begin{lstlisting}[language=r,numbers=none]
calciumW$change2 <- calciumW$bmd2 - calciumW$bmd1
calciumW$change3 <- calciumW$bmd3 - calciumW$bmd1
calciumW$change4 <- calciumW$bmd4 - calciumW$bmd1
calciumW$change5 <- calciumW$bmd5 - calciumW$bmd1
calciumL$change <- calciumL$bmd - calciumL$baseline
\end{lstlisting}


For illustrative purpose, we will restrict both dataset to subjects
with complete data:
\begin{lstlisting}[language=r,numbers=none]
calciumW.NNA <- calciumW[rowSums(is.na(calciumW))==0,]
calciumL.NNA <- calciumL[calciumL$girl %in% calciumW.NNA$girl,]
\end{lstlisting}

as the aim is to show equivalence between statistical tests when there
is no missing data. 

\clearpage
\section{Test on the mean}
\label{sec:org2658eab}
\subsection{Welch two sample t-test}
\label{sec:org3c5211e}

A two sample t-test:
\begin{lstlisting}[language=r,numbers=none]
with(abetaW, t.test(x = pss0[group=="BD"], y = pss0[group=="HC"]))
\end{lstlisting}

\phantomsection
\label{}
\begin{verbatim}

	Welch Two Sample t-test

data:  pss0[group == "BD"] and pss0[group == "HC"]
t = 5.67, df = 112, p-value = 1.1e-07
alternative hypothesis: true difference in means is not equal to 0
95 percent confidence interval:
 3.8988 8.0906
sample estimates:
mean of x mean of y 
  13.2674    7.2727
\end{verbatim}

is equivalent to a linear regression with a group-specific residual
variance:
\begin{lstlisting}[language=r,numbers=none]
abetaW$group <- relevel(abetaW$group,"HC")
e.ttest <- lmm(pss0 ~ group, structure = IND(~group), 
               data = abetaW, trace = FALSE)
model.tables(e.ttest, effects = "all")
\end{lstlisting}

\phantomsection
\label{}
\begin{verbatim}
            estimate      se      df  lower  upper    p.value
(Intercept)   7.2727 0.75788  43.009 5.7443 8.8011 2.9650e-12
groupBD       5.9947 1.05781 112.201 3.8988 8.0906 1.1399e-07
sigma         5.0272 0.54210  43.009 4.0447 6.2484         NA
k.BD          1.3613 0.18014  86.351 1.0464 1.7709 2.2090e-02
\end{verbatim}


\noindent For comparison a linear model would estimate different standard
errors, degrees of freedom, and p-values:
\begin{lstlisting}[language=r,numbers=none]
model.tables(lmm(pss0 ~ group, data = abetaW))
\end{lstlisting}

\phantomsection
\label{}
\begin{verbatim}
            estimate      se     df  lower  upper    p.value
(Intercept)   7.2727 0.94857 128.03 5.3958 9.1496 3.8629e-12
groupBD       5.9947 1.16625 128.03 3.6871 8.3023 1.0000e-06
\end{verbatim}


as it does not account for heteroschedasticity. This makes the
'heteroschedastic linear regression' \texttt{e.ttest} a natural extension of
the t-test when it comes to account for covariates.

\clearpage

In the special case of two groups of equal size, the standard errors
estimated accounting for heteroschedasticity:
\begin{lstlisting}[language=r,numbers=none]
model.tables(lmm(pss0 ~ group, structure = IND(~group), 
                 data = abetaW.B, trace = FALSE))
\end{lstlisting}

\phantomsection
\label{}
\begin{verbatim}
            estimate      se     df   lower   upper    p.value
(Intercept)  11.8636 0.98648 43.009  9.8742 13.8530 2.4425e-15
groupHC      -4.5909 1.24399 80.661 -7.0662 -2.1156 4.0523e-04
\end{verbatim}


or ignoring it:
\begin{lstlisting}[language=r,numbers=none]
model.tables(lmm(pss0 ~ group, data = abetaW.B))
\end{lstlisting}

\phantomsection
\label{}
\begin{verbatim}
            estimate      se     df   lower   upper    p.value
(Intercept)  11.8636 0.87964 86.017 10.1150 13.6123 0.00000000
groupHC      -4.5909 1.24399 86.017 -7.0639 -2.1179 0.00039184
\end{verbatim}


will be the same, leading to very similar p-values (degrees of freedom
differ slightly).

\clearpage
\subsection{Paired t-test}
\label{sec:org708984c}

With complete data, a paired t-test:
\begin{lstlisting}[language=r,numbers=none]
t.test(calciumW.NNA$bmd2, calciumW.NNA$bmd1, paired = TRUE)
\end{lstlisting}

\phantomsection
\label{}
\begin{verbatim}

	Paired t-test

data:  calciumW.NNA$bmd2 and calciumW.NNA$bmd1
t = 13, df = 90, p-value <2e-16
alternative hypothesis: true mean difference is not equal to 0
95 percent confidence interval:
 20.229 27.529
sample estimates:
mean difference 
         23.879
\end{verbatim}

is equivalent to a LMM with an unstructured covariate pattern:
\begin{lstlisting}[language=r,numbers=none]
e.lmm2tt <- lmm(bmd ~ visit, repetition = ~visit|girl, structure = "UN",
                data = calciumL.NNA)
model.tables(e.lmm2tt)["visit2",,drop=FALSE]
\end{lstlisting}

\phantomsection
\label{}
\begin{verbatim}
       estimate     se     df  lower  upper p.value
visit2   23.879 1.8371 89.968 20.229 27.529       0
\end{verbatim}


\clearpage
\subsection{Comparing change}
\label{sec:org396095b}
\subsubsection{Using a Welch two sample t-test}
\label{sec:org5d0ef5a}

With complete data, a two sample t-test comparing the change from baseline:
\begin{lstlisting}[language=r,numbers=none]
ttc <- with(calciumW.NNA, t.test(x = change2[grp=="C"], y = change2[grp=="P"]))
ttc
\end{lstlisting}

\phantomsection
\label{}
\begin{verbatim}

	Welch Two Sample t-test

data:  change2[grp == "C"] and change2[grp == "P"]
t = 2.03, df = 88.8, p-value = 0.046
alternative hypothesis: true difference in means is not equal to 0
95 percent confidence interval:
  0.14074 14.49659
sample estimates:
mean of x mean of y 
   27.659    20.340
\end{verbatim}

is equivalent to a LMM with a stratified unstructured covariate pattern:
\begin{lstlisting}[language=r,numbers=none]
e.lmm2tt2 <- lmm(bmd ~ visit*grp, repetition = ~visit|girl, structure = UN(~grp),
                 data = calciumL.NNA)
model.tables(e.lmm2tt2)[c("visit2","visit2:grpC"),,drop=FALSE]
\end{lstlisting}

\phantomsection
\label{}
\begin{verbatim}
            estimate     se     df    lower  upper    p.value
visit2       20.3404 2.5338 46.005 15.24013 25.441 2.6911e-10
visit2:grpC   7.3187 3.6124 88.734  0.14069 14.497 4.5767e-02
\end{verbatim}


The estimate and standard error are exactly the same:
\begin{lstlisting}[language=r,numbers=none]
c(ttc$estimate["mean of x"] - ttc$estimate["mean of y"],
  se = ttc$stderr)
\end{lstlisting}

\phantomsection
\label{}
\begin{verbatim}
mean of x        se 
   7.3187    3.6124
\end{verbatim}


The only (small) difference lies in the estimation of the degrees of freedom.

\clearpage
\subsubsection{Using a linear regression}
\label{sec:org35cc122}

Using a linear model to compare change over time:
\begin{lstlisting}[language=r,numbers=none]
eLM.change <- lm(change2 ~ grp, data = calciumW.NNA)
summary(eLM.change)$coef
\end{lstlisting}

\phantomsection
\label{}
\begin{verbatim}
            Estimate Std. Error t value   Pr(>|t|)
(Intercept)  20.3404     2.5133  8.0931 2.7975e-12
grpC          7.3187     3.6144  2.0249 4.5878e-02
\end{verbatim}


is equivalent to the following mixed model:
\begin{lstlisting}[language=r,numbers=none]
eLMM.change <- lmm(bmd ~ visit*grp,
                   repetition =~ visit|girl, structure = UN,
                   data = calciumL.NNA)
model.tables(eLMM.change)[c("visit2","visit2:grpC"),]
\end{lstlisting}

\phantomsection
\label{}
\begin{verbatim}
            estimate     se     df    lower  upper    p.value
visit2       20.3404 2.5133 88.962 15.34654 25.334 2.8044e-12
visit2:grpC   7.3187 3.6144 88.962  0.13688 14.500 4.5880e-02
\end{verbatim}


Here, since the linear regression assumes the same variance in both
groups, we did not stratified the covariance pattern on group. The
same equivalence would hold with a continuous exposure (say dose)
instead of a binary exposure (here \texttt{grp}).

\bigskip

In presence of a covariate:
\begin{lstlisting}[language=r,numbers=none]
set.seed(1)
calciumW2.NNA <- cbind(calciumW.NNA,
                       age = round(runif(NROW(calciumW.NNA), min = 18, max = 60)))
calciumL2.NNA <- merge(calciumL.NNA, calciumW2.NNA[,c("girl","age")], by = "girl")

eLMadj.change <- lm(change2 ~ grp + age, data = calciumW2.NNA)
summary(eLMadj.change)$coef
\end{lstlisting}

\phantomsection
\label{}
\begin{verbatim}
            Estimate Std. Error t value Pr(>|t|)
(Intercept)  9.17495    6.68052  1.3734 0.173121
grpC         6.99548    3.57426  1.9572 0.053495
age          0.28771    0.15982  1.8002 0.075251
\end{verbatim}


one should specify interaction with time in the mixed model to
retrieve the same results:
\begin{lstlisting}[language=r,numbers=none]
eLMMadj.change <- lmm(bmd ~ visit*grp + visit*age,
                      repetition =~ visit|girl, structure = UN,
                      data = calciumL2.NNA)
model.tables(eLMMadj.change)[c("visit2","visit2:grpC"),]
\end{lstlisting}

\phantomsection
\label{}
\begin{verbatim}
            estimate     se     df    lower  upper  p.value
visit2        9.1750 6.6805 87.966 -4.10126 22.451 0.173122
visit2:grpC   6.9955 3.5743 87.966 -0.10764 14.099 0.053497
\end{verbatim}



\clearpage
\subsection{Multiple Student's t-test}
\label{sec:orga0b6149}

To adjust several t-tests for multiple testing, one can use the
equivalence with \texttt{lmm}. This however require to specify the structure
of the data (via the argument \texttt{repetition}), i.e., at which level
replicates are independent so the software can deduce the appropriate
number of independent observation across t-tests:

\begin{lstlisting}[language=r,numbers=none]
e.ttest2 <- lmm(change2 ~ grp, structure = IND(~grp), 
                data = calciumW, repetition = ~1|girl, trace = FALSE)
e.ttest3 <- lmm(change3 ~ grp, structure = IND(~grp), 
                data = calciumW, repetition = ~1|girl, trace = FALSE)
e.ttest4 <- lmm(change4 ~ grp, structure = IND(~grp), 
                data = calciumW, repetition = ~1|girl, trace = FALSE)
e.ttest5 <- lmm(change5 ~ grp, structure = IND(~grp), 
                data = calciumW, repetition = ~1|girl, trace = FALSE)
\end{lstlisting}

\noindent The \texttt{anova} method is then used to specify the parameter of
 interest and the results combined using \texttt{rbind}:
\begin{lstlisting}[language=r,numbers=none]
e.mttest <- rbind(anova(e.ttest2, effects = "grpC=0"),
                  anova(e.ttest3, effects = "grpC=0"),
                  anova(e.ttest4, effects = "grpC=0"),
                  anova(e.ttest5, effects = "grpC=0"))
model.tables(e.mttest, method = "single-step2")
\end{lstlisting}

\phantomsection
\label{}
\begin{verbatim}
                estimate     se      df   lower  upper  p.value
change2: grpC=0   6.7507 3.3549 103.014 -1.2191 14.721 0.112799
change3: grpC=0  13.8150 4.8336  95.812  2.3321 25.298 0.014660
change4: grpC=0  12.5190 5.8369  86.835 -1.3473 26.385 0.084529
change5: grpC=0  19.0155 6.4666  86.916  3.6533 34.378 0.011440
\end{verbatim}


\uline{Note:} the \texttt{single-step2} adjustment is similar to the \texttt{single-step}
adjustment of the multcomp package, i.e., a max test adjustment. But
instead of relying on the density of a multivariate Student's
t-distribution, which requires equal degrees of freedom, it samples in
a multivariate distribution with Student's t marginal possibly based
on different degrees of freedom and a Gaussian copula. Being based on
random sampling, results will slightly change everytime the code is
run unless the inital state of the random number generator is set to a
specific value before running the code:

\begin{lstlisting}[language=r,numbers=none]
set.seed(1)
model.tables(e.mttest, method = "single-step2")
\end{lstlisting}

\phantomsection
\label{}
\begin{verbatim}
                estimate     se      df   lower  upper  p.value
change2: grpC=0   6.7507 3.3549 103.014 -1.2151 14.717 0.113439
change3: grpC=0  13.8150 4.8336  95.812  2.3379 25.292 0.014590
change4: grpC=0  12.5190 5.8369  86.835 -1.3404 26.378 0.085339
change5: grpC=0  19.0155 6.4666  86.916  3.6609 34.370 0.011640
\end{verbatim}



\hspace{-5mm}\begin{minipage}[t]{0.5\linewidth}
The \texttt{LMMstar.options} function can be used \newline
to output the number of samples used:
\begin{lstlisting}[language=r,numbers=none]
LMMstar.options()$n.sampleCopula
\end{lstlisting}

\phantomsection
\label{}
\begin{verbatim}
[1] 1e+05
\end{verbatim}


\end{minipage}
\begin{minipage}[t]{0.45\linewidth}
\hphantom{x} \newline and change it:
\begin{lstlisting}[language=r,numbers=none]
LMMstar.options(n.sampleCopula = 1e4)
\end{lstlisting}
\end{minipage}

\bigskip

This whole procedure can be streamlined using the long format and the
\texttt{mlmm} function:
\begin{itemize}
\item the argument \texttt{by} indicates how to split the data. A separate model
is fitted on each split.
\item the argument \texttt{effects} indicates the test to be extracted for each
model.
\item the argument \texttt{name.short} is a cosmetic argument: should the name of
each test be the covariate value or a combination of the covariate
variable and the covariate value?
\end{itemize}
\begin{lstlisting}[language=r,numbers=none]
e.mttest2 <- mlmm(change ~ grp, structure = IND(~grp), repetition = ~visit|girl,
                  data = calciumL[calciumL$visit!=1,], trace = FALSE,
                  by = "visit", effects = "grpC=0", name.short = FALSE)
set.seed(1)
model.tables(e.mttest, method = "single-step2")
\end{lstlisting}



\phantomsection
\label{}
\begin{verbatim}
                estimate     se      df   lower  upper  p.value
change2: grpC=0   6.7507 3.3549 103.014 -1.2151 14.717 0.113439
change3: grpC=0  13.8150 4.8336  95.812  2.3379 25.292 0.014590
change4: grpC=0  12.5190 5.8369  86.835 -1.3404 26.378 0.085339
change5: grpC=0  19.0155 6.4666  86.916  3.6609 34.370 0.011640
\end{verbatim}


The function \texttt{mlmm} can be used not only to emulate multiple t-tests
but also for multiple linear regressions or linear mixed models. In
the special case of multiple Welch two-sample test, a dedicated
function \texttt{mt.test} offers a more user friendly interface:
\begin{lstlisting}[language=r,numbers=none]
set.seed(1)
mt.test(change2 + change3 + change4 + change5 ~ grp, data = calciumW)
\end{lstlisting}

\phantomsection
\label{}
\begin{verbatim}
Argument 'data' contains 59 missing values. 
        estimate     se      df   lower  upper  p.value
change2   6.7507 3.3549 103.014 -1.2151 14.717 0.113439
change3  13.8150 4.8336  95.812  2.3379 25.292 0.014590
change4  12.5190 5.8369  86.835 -1.3404 26.378 0.085339
change5  19.0155 6.4666  86.916  3.6609 34.370 0.011640
\end{verbatim}


\clearpage
\subsection{ANCOVA}
\label{sec:orgb9651d7}

Instead of comparing the final value or the change between groups
using a Welch two sample t-test, the ANCOVA is often refered to as the
superior approach to assess a treatment effect
\citep{vickers2001analysing}. It regresses the group variable and the
baseline value against the change:

\begin{lstlisting}[language=r,numbers=none]
model.tables(lmm(change2 ~ bmd1 + grp, data = calciumW.NNA))
\end{lstlisting}

\phantomsection
\label{}
\begin{verbatim}
              estimate        se     df      lower    upper  p.value
(Intercept) -25.742684 25.757918 88.018 -76.930991 25.44562 0.320337
bmd1          0.052948  0.029457 88.018  -0.005592  0.11149 0.075693
grpC          6.741021  3.584377 88.018  -0.382155 13.86420 0.063324
\end{verbatim}


or the final value:
\begin{lstlisting}[language=r,numbers=none]
model.tables(lmm(bmd2 ~ bmd1 + grp, data = calciumW.NNA))
\end{lstlisting}

\phantomsection
\label{}
\begin{verbatim}
            estimate        se     df     lower   upper  p.value
(Intercept) -25.7427 25.757918 88.018 -76.93099 25.4456 0.320337
bmd1          1.0529  0.029457 88.018   0.99441  1.1115 0.000000
grpC          6.7410  3.584377 88.018  -0.38215 13.8642 0.063324
\end{verbatim}


both leading to equivalent result. The corresponding mixed model
constrains the both group to take the same baseline value. This can be
specified by introducing a new covariate that only differ between
groups after baseline:
\begin{lstlisting}[language=r,numbers=none]
calciumL.NNA$trt <- ifelse(calciumL.NNA$visit==1,"P",as.character(calciumL.NNA$grp))
calciumL.NNA$trt <- factor(calciumL.NNA$trt, levels = c("P","C"))
ftable(grp = calciumL.NNA$grp, trt = calciumL.NNA$trt, visit = calciumL.NNA$visit)
\end{lstlisting}

\phantomsection
\label{}
\begin{verbatim}
        visit  1  2  3  4  5
grp trt                     
P   P         47 47 47 47 47
    C          0  0  0  0  0
C   P         44  0  0  0  0
    C          0 44 44 44 44
\end{verbatim}


We then retrieve the same estimate and similar (but not identical)
standard errors and p-values with the following mixed model:
\begin{lstlisting}[language=r,numbers=none]
e.lmmANCOVA <- lmm(bmd ~ visit*trt, repetition = ~visit|girl, structure = UN,
                   data = calciumL.NNA)
model.tables(e.lmmANCOVA)["visit2:trtC",,drop=FALSE]
\end{lstlisting}

\phantomsection
\label{}
\begin{verbatim}
Constant values in the design matrix for the mean structure.
Coefficient "trtC" relative to interaction "visit:trt" has been removed.
            estimate     se     df   lower  upper  p.value
visit2:trtC    6.741 3.5642 88.853 -0.3411 13.823 0.061839
\end{verbatim}


\clearpage

To avoid the message about the design matrix, one should 'manually'
define the interaction terms:
\begin{lstlisting}[language=r,numbers=none]
calciumL.NNA$visit.trt <- ifelse(calciumL.NNA$trt == "C", calciumL.NNA$visit, "baseline")
calciumL.NNA$visit.trt <- factor(calciumL.NNA$visit.trt, levels = c("baseline",2:5))
ftable(grp = calciumL.NNA$grp, visit.trt = calciumL.NNA$visit.trt, visit = calciumL.NNA$visit)
\end{lstlisting}

\phantomsection
\label{}
\begin{verbatim}
              visit  1  2  3  4  5
grp visit.trt                     
P   baseline        47 47 47 47 47
    2                0  0  0  0  0
    3                0  0  0  0  0
    4                0  0  0  0  0
    5                0  0  0  0  0
C   baseline        44  0  0  0  0
    2                0 44  0  0  0
    3                0  0 44  0  0
    4                0  0  0 44  0
    5                0  0  0  0 44
\end{verbatim}

\begin{lstlisting}[language=r,numbers=none]
e.lmmANCOVA2 <- lmm(bmd ~ visit + visit.trt, repetition = ~visit|girl, structure = UN,
                   data = calciumL.NNA)
model.tables(e.lmmANCOVA2)["visit.trt2",,drop=FALSE]
\end{lstlisting}

\phantomsection
\label{}
\begin{verbatim}
           estimate     se     df   lower  upper  p.value
visit.trt2    6.741 3.5642 88.853 -0.3411 13.823 0.061839
\end{verbatim}


As before, in presence of a covariate:
\begin{lstlisting}[language=r,numbers=none]
summary(lm(bmd2 ~ bmd1 + grp + age, data = calciumW2.NNA))$coef
\end{lstlisting}

\phantomsection
\label{}
\begin{verbatim}
            Estimate Std. Error t value   Pr(>|t|)
(Intercept) -37.6452  26.215165 -1.4360 1.5459e-01
bmd1          1.0536   0.029064 36.2524 2.7566e-54
grpC          6.4062   3.540822  1.8093 7.3865e-02
age           0.2914   0.157689  1.8479 6.8008e-02
\end{verbatim}


one should add the covariate along with time interactions to retrieve
the same estimate and similar standard error/p-value/confindence
intervals with a linear mixed model:
\begin{lstlisting}[language=r,numbers=none]
calciumL2.NNA$visit.trt <- ifelse(calciumL2.NNA$grp == "C", calciumL.NNA$visit, "1")

e.lmmANCOVAadj <- lmm(bmd ~ visit + visit.trt + visit*age, repetition = ~visit|girl,
                      structure = UN, data = calciumL2.NNA)
model.tables(e.lmmANCOVAadj)["visit.trt2",,drop=FALSE]
\end{lstlisting}

\phantomsection
\label{}
\begin{verbatim}
           estimate     se     df    lower  upper  p.value
visit.trt2   6.4062 3.5206 87.855 -0.59046 13.403 0.072223
\end{verbatim}


\clearpage


\noindent A natural extension of the ANCOVA would be to relax the
assumption of common residual variance between the two treatment
groups:
\begin{lstlisting}[language=r,numbers=none]
model.tables(lmm(change2 ~ bmd1 + grp, data = calciumW.NNA, structure = IND(~grp)))
\end{lstlisting}

\phantomsection
\label{}
\begin{verbatim}
              estimate        se     df       lower    upper  p.value
(Intercept) -25.833272 25.805339 83.926 -77.1506784 25.48413 0.319665
bmd1          0.053052  0.029513 84.179  -0.0056359  0.11174 0.075828
grpC          6.739886  3.585265 87.584  -0.3855470 13.86532 0.063448
\end{verbatim}


However the 'straightforward' connexion with mixed model seems lost:
\begin{lstlisting}[language=r,numbers=none]
e.lmmHANCOVA <- lmm(bmd ~ visit + visit.trt, repetition = ~visit|girl, structure = UN(~grp),
                    data = calciumL.NNA)
model.tables(e.lmmHANCOVA)["visit.trt2",,drop=FALSE]
\end{lstlisting}

\phantomsection
\label{}
\begin{verbatim}
           estimate     se     df    lower  upper  p.value
visit.trt2   6.7516 3.5654 88.326 -0.33341 13.837 0.061542
\end{verbatim}


\clearpage
\section{Test on the correlation}
\label{sec:orge235a42}

\subsection{Person's correlation}
\label{sec:org5102c38}

One can retrieve Pearson's correlation:
\begin{lstlisting}[language=r,numbers=none]
cor.test(calciumW.NNA$bmd1,calciumW.NNA$bmd5)
\end{lstlisting}

\phantomsection
\label{}
\begin{verbatim}

	Pearson's product-moment correlation

data:  calciumW.NNA$bmd1 and calciumW.NNA$bmd5
t = 18.3, df = 89, p-value <2e-16
alternative hypothesis: true correlation is not equal to 0
95 percent confidence interval:
 0.83615 0.92551
sample estimates:
    cor 
0.88901
\end{verbatim}

using a linear mixed model moving to the long format and using an
unstructured mean and covariance pattern over time:
\begin{lstlisting}[language=r,numbers=none]
eCor.lmm <- lmm(bmd ~ visit, repetition = ~visit|girl,
                structure = UN, data = calciumL.NNA)
model.tables(eCor.lmm,  effects = "correlation")["rho(1,5)",]
\end{lstlisting}

\phantomsection
\label{}
\begin{verbatim}
         estimate     se     df   lower   upper p.value
rho(1,5)  0.88901 0.0221 96.839 0.83607 0.92555       0
\end{verbatim}


P-value and confidence interval will differ (only slightly in large
samples) because \texttt{cor.test} uses an exact\footnote{assuming jointly
normally distributed outcomes} formula for the variance after \texttt{atanh}
transformation while the linear mixed model rely on the observed
information matrix. In this example the observed information (default
option) is more in line with \texttt{cor.test} than the expected information:
\begin{lstlisting}[language=r,numbers=none]
model.tables(eCor.lmm,  type.information = "expected", effects = "correlation")["rho(1,5)",]
\end{lstlisting}

\phantomsection
\label{}
\begin{verbatim}
         estimate       se       df   lower   upper p.value
rho(1,5)  0.88901 0.021914 17285033 0.83738 0.92492       0
\end{verbatim}


Of note the confidence intervals and p-value of \texttt{cor.test} are not
computed in a consistent way: 
\begin{lstlisting}[language=r,numbers=none]
set.seed(7303)
X <- rnorm(10)
Y <- rnorm(10)
cor.test(X,Y)
\end{lstlisting}

\phantomsection
\label{}
\begin{verbatim}

	Pearson's product-moment correlation

data:  X and Y
t = 2.29, df = 8, p-value = 0.051
alternative hypothesis: true correlation is not equal to 0
95 percent confidence interval:
 0.00016154 0.90179629
sample estimates:
    cor 
0.62972
\end{verbatim}

\noindent Here the confidence intervals do not overlap 0, i.e.,
suggest to reject the null hypothesis while the p-value is greater
than 0.05, i.e., does not suggest to reject the null hypothesis. The
corresponding mixed model estimate:
\begin{lstlisting}[language=r,numbers=none]
dfXY <- rbind(data.frame(value = X, variable = "x", id = 1:10),
              data.frame(value = Y, variable = "y", id = 1:10))
e.lmmXY <- lmm(value ~ variable, repetition = ~variable|id,
               structure = UN, data = dfXY)
model.tables(e.lmmXY, effects = "correlation")
\end{lstlisting}

\phantomsection
\label{}
\begin{verbatim}
         estimate      se     df     lower   upper  p.value
rho(x,y)  0.62972 0.20115 7.0024 -0.047159 0.91027 0.061602
\end{verbatim}


is the same but the confidence intervals and p-value differ more
substantially (due to small sample approximations). They however are
consistent with respect to whether to reject the null hypothesis.

\clearpage
\subsection{Comparing Person's correlations}
\label{sec:orgbc78b3d}

To compare the Pearson's correlation between two groups, one can use
Fisher'z test:
\begin{lstlisting}[language=r,numbers=none]
rho.C <- with(calciumW.NNA, cor(bmd1[grp=="C"],bmd5[grp=="C"]))
rho.P <- with(calciumW.NNA, cor(bmd1[grp=="P"],bmd5[grp=="P"]))
nobs.C <- sum(calciumW$grp=="C")
nobs.P <- sum(calciumW$grp=="P")
stat.fisher <- (atanh(rho.C) - atanh(rho.P))/sqrt(1/(nobs.C-3)+1/(nobs.P-3))
2*(1-pnorm(abs(stat.fisher)))
\end{lstlisting}

\phantomsection
\label{}
\begin{verbatim}
[1] 0.15261
\end{verbatim}


and the confidence intervals suggested by \cite{zou2007toward}:
\begin{lstlisting}[language=r,numbers=none]
zou.C <- tanh(atanh(rho.C) + qnorm(c(0.025,0.975))/sqrt(nobs.C-3))
zou.P <- tanh(atanh(rho.P) + qnorm(c(0.025,0.975))/sqrt(nobs.P-3))

(rho.C - rho.P) - sqrt( (rho.C-zou.C[1])^2 + (rho.P-zou.P[2])^2 )
(rho.C - rho.P) + sqrt( (rho.C-zou.C[2])^2 + (rho.P-zou.P[1])^2 )
\end{lstlisting}

\phantomsection
\label{}
\begin{verbatim}
[1] -0.15309
[1] 0.021034
\end{verbatim}


which is implemented in the package cocor:
\begin{lstlisting}[language=r,numbers=none]
library(cocor)
cocor.indep.groups(r1.jk = rho.C, n1 = nobs.C, r2.hm = rho.P, n2 = nobs.P)
\end{lstlisting}

\phantomsection
\label{}
\begin{verbatim}

  Results of a comparison of two correlations based on independent groups

Comparison between r1.jk = 0.8597 and r2.hm = 0.917
Difference: r1.jk - r2.hm = -0.0574
Group sizes: n1 = 55, n2 = 57
Null hypothesis: r1.jk is equal to r2.hm
Alternative hypothesis: r1.jk is not equal to r2.hm (two-sided)
Alpha: 0.05

fisher1925: Fisher's z (1925)
  z = -1.4304, p-value = 0.1526
  Null hypothesis retained

zou2007: Zou's (2007) confidence interval
  95% confidence interval for r1.jk - r2.hm: -0.1531 0.0210
  Null hypothesis retained (Interval includes 0)
\end{verbatim}

We can retrieve the same estimated difference and similar but not
identical CIs/p-values using a linear mixed model with a covariance
pattern stratified on group:
\begin{lstlisting}[language=r,numbers=none]
eCor2.lmm <- lmm(bmd ~ visit*grp, repetition = ~visit|girl,
                structure = UN(~grp), data = calciumL.NNA)
model.tables(eCor2.lmm,  effects = "correlation")[c("rho(1,5):C","rho(1,5):P"),]
\end{lstlisting}

\phantomsection
\label{}
\begin{verbatim}
           estimate       se     df   lower   upper    p.value
rho(1,5):C  0.85965 0.039801 42.111 0.75492 0.92163 1.2128e-10
rho(1,5):P  0.91701 0.023456 53.835 0.85496 0.95319 7.3275e-15
\end{verbatim}


and use a Wald test to compare the correlation coefficients:
\begin{lstlisting}[language=r,numbers=none]
set.seed(1)
summary(anova(eCor2.lmm, effects = "rho(1,5):C - rho(1,5):P = 0"), digits = 4)
\end{lstlisting}

\phantomsection
\label{}
\begin{verbatim}
            Wald F-test 

       statistic       df p.value  
   all    1.7165 (1,93.6)   0.193  
   ------------------------------- 
    :  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1.
  df: Satterthwaite approximation w.r.t. model-based se. 

		Emulated Wald test (resampling parameter distribution) 

                               estimate     se   df   lower upper p.value  
   rho(1,5):C - rho(1,5):P = 0  -0.0574 0.0495 <NA> -0.1661  0.03   0.197  
   ------------------------------------------------------------------ 
    :  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1.
  se: based on the observed information (model-based). 
  Back-transformation: rho parameters with atanh (1e+05 samples).
\end{verbatim}

The 'Wald F-test' is the usual Wald test defined by the squared
difference between the two correlation coefficients divided by the
squared standard error of this difference. This ratio follows, under
the null hypothesis, an F-distribution which is used to obtain a
p-value. The 'Emulated Wald test' attempts to provide a confidence
interval for the difference compatible with the p-value. As mentionned
in the litterature \citep{zou2007toward}, a 'naive' back-transformation
of the difference would not provide confidence intervals with good
frequentist properties (intuitively \(tanh(atanh(y)-atanh(x))\neq y -
x\)). Instead samples are drawn from a bivariate Student's t
distribution distribution centered around 0 and with
variance-covariance matrix the inverse of the observed information on
the \texttt{atanh} scale.
\begin{itemize}
\item \texttt{p.value}: relative frequency of a difference in simulated
correlations more extreme than observed. It should be close to the
p-value of the Wald F-test'.
\item \texttt{se}: standard deviation of the simulated difference in correlation
on the original scale
\item \texttt{lower}, \texttt{upper}: quantiles of the simulated difference in
correlation on the original scale after centering the simulated
values on the \texttt{atanh} scale around the estimated correlation.
\end{itemize}

\clearpage

The \texttt{partialCor} method provides a more straightforward syntax to do
the later test is:

\begin{lstlisting}[language=r,numbers=none]
set.seed(1)
partialCor(bmd1 + bmd5 ~ 1, data = calciumW.NNA, by = "grp", effects = "Dunnett") 
\end{lstlisting}

\phantomsection
\label{}
\begin{verbatim}
      estimate     se df  lower upper p.value
C - P  -0.0574 0.0491 NA -0.165 0.029   0.195
\end{verbatim}


The methodology is the same, except that the underlying mixed model is
based on two timepoints (1 and 5) instead of all timepoints
(1,2,3,4,5).
\bigskip

It is also possible to not use any transformation: 
\begin{lstlisting}[language=r,numbers=none]
testRho <- anova(eCor2.lmm, effects = "rho(1,5):C - rho(1,5):P = 0", transform.rho = "none")
summary(testRho, print = TRUE)
\end{lstlisting}

\phantomsection
\label{}
\begin{verbatim}
		Wald F-test 

       statistic      df p.value  
   all     1.542 (1,3.7)   0.288  
   ------------------------------ 
    :  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1.
  df: Satterthwaite approximation w.r.t. model-based se. 

		Hypothesis-specific Wald test 

                               estimate    se  df lower upper p.value  
   rho(1,5):C - rho(1,5):P = 0   -0.057 0.046 3.7 -0.19 0.076   0.288  
   ------------------------------------------------------------------- 
    :  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1.
  df: Satterthwaite approximation w.r.t. model-based se. 
  se: based on the observed information (model-based).
\end{verbatim}

but this is expected to have worse small sample properties compared to
using a transformation. In this example the estimated p-value is also
further away from the Fisher'z test. Here the 'Hypothesis-specific
Wald test' uses a Student's t-distribution to model the distribution
of the ratio between the estimate and the standard error. This is
exactly the square root (up to a sign) of the Wald F-test test
statistic, leading to exactly the same p-value and compatible
confidence intervals.

\clearpage
\subsection{Correlation between changes}
\label{sec:org5cec876}

In some studies, one is interested in studying the relation between
two evolutions. Say the change from baseline in quality of life
vs. functioning assessment test:
\begin{lstlisting}[language=r,numbers=none]
abetaW$dqol <- abetaW$qol1 - abetaW$qol0
abetaW$dfast <- abetaW$fast1 - abetaW$fast0
abetaW.NNA <- abetaW[!is.na(abetaW$dqol) & !is.na(abetaW$dfast),]
\end{lstlisting}

\bigskip

One can evaluate their correlation:
\begin{lstlisting}[language=r,numbers=none]
cor.test(abetaW.NNA$dqol, abetaW.NNA$dfast)
\end{lstlisting}

\phantomsection
\label{}
\begin{verbatim}

	Pearson's product-moment correlation

data:  abetaW.NNA$dqol and abetaW.NNA$dfast
t = -4.27, df = 110, p-value = 4.2e-05
alternative hypothesis: true correlation is not equal to 0
95 percent confidence interval:
 -0.52570 -0.20575
sample estimates:
     cor 
-0.37692
\end{verbatim}

or estimate the regression coefficient of one change against the
other:
\begin{lstlisting}[language=r,numbers=none]
model.tables(lmm(dqol ~ dfast, data = abetaW.NNA))
\end{lstlisting}

\phantomsection
\label{}
\begin{verbatim}
            estimate      se     df    lower    upper    p.value
(Intercept)  1.34601 0.85087 110.02 -0.34022  3.03224 1.1654e-01
dfast       -0.49231 0.11535 110.02 -0.72091 -0.26371 4.1977e-05
\end{verbatim}


To retrieve the same results using a linear mixed model, one should
move the dataset to the very long format, where each type of
measurement is treated as a separate outcome:
\begin{lstlisting}[language=r,numbers=none]
abetaL.NNA <- reshape(abetaW.NNA[,c("id","qol0","qol1","fast0","fast1")], direction = "long",
                      idvar = "id", varying = 2:5,
                      timevar = "type", times = c("qol0","qol1","fast0","fast1"), v.names = c("value"))
abetaL.NNA <- abetaL.NNA[order(abetaL.NNA$id),]
rownames(abetaL.NNA) <- NULL
head(abetaL.NNA)
\end{lstlisting}

\phantomsection
\label{}
\begin{verbatim}
  id  type value
1  3  qol0    86
2  3  qol1    79
3  3 fast0    29
4  3 fast1    31
5  4  qol0    96
6  4  qol1   101
\end{verbatim}


One can then jointly model the association between all type of
measurement using an unstructured residual variance-covariance matrix:
\begin{lstlisting}[language=r,numbers=none]
e.lmm4 <- lmm(value ~ type,
              repetition = ~type|id, structure = "UN",
              data = abetaL.NNA)
sigma.lmm4 <- sigma(e.lmm4)
sigma.lmm4
\end{lstlisting}

\phantomsection
\label{}
\begin{verbatim}
        fast0   fast1    qol0    qol1
fast0 132.471  95.090 -97.958 -72.709
fast1  95.090 102.301 -75.656 -72.360
qol0  -97.958 -75.656 143.759  91.321
qol1  -72.709 -72.360  91.321 114.957
\end{verbatim}


Deduce the residual covariance matrix for the change:
\begin{lstlisting}[language=r,numbers=none]
Mcon <- cbind(c(-1,1,0,0),c(0,0,-1,1))
sigmeChange.lmm4 <- t(Mcon) %*% sigma.lmm4 %*% Mcon
dimnames(sigmeChange.lmm4) <- replicate(2,c("dfast","dqol"), simplify = FALSE)
sigmeChange.lmm4
\end{lstlisting}

\phantomsection
\label{}
\begin{verbatim}
        dfast    dqol
dfast  44.592 -21.953
dqol  -21.953  76.075
\end{verbatim}


and retrieve the corrrelation and regression coefficients:
\begin{lstlisting}[language=r,numbers=none]
cov2cor(sigmeChange.lmm4)[1,2]
sigmeChange.lmm4[1,2]/sigmeChange.lmm4[1,1]
\end{lstlisting}

\phantomsection
\label{}
\begin{verbatim}
[1] -0.37692
[1] -0.49231
\end{verbatim}


The uncertainty can be quantified using a delta method:
\begin{lstlisting}[language=r,numbers=none]
estimate(e.lmm4, function(p){
  Sigma.change <- t(Mcon) %*% sigma(e.lmm4, p = p) %*% Mcon
  c(cor = cov2cor(Sigma.change)[1,2],
    beta = Sigma.change[1,2]/Sigma.change[1,1])
})
\end{lstlisting}

\phantomsection
\label{}
\begin{verbatim}
     estimate       se     df    lower    upper    p.value
cor  -0.37692 0.081429 12.075 -0.55421 -0.19962 0.00057192
beta -0.49231 0.114833 12.561 -0.74127 -0.24334 0.00095359
\end{verbatim}


The standard error for the regression coefficient is close to the
linear model one but the degrees of freedom seem grossly
underestimated. One can set the argument \texttt{df} to \texttt{FALSE} when calling
\texttt{estimate} to use a Gaussian instead of a Student's t distribution.

\clearpage
\section{Test on the variance}
\label{sec:org0230009}

\subsection{Comparing variances}
\label{sec:org3cc7c12}

We can emulate a F-test comparing the variance between two populations:
\begin{lstlisting}[language=r,numbers=none]
var.test(x = calciumW.NNA[calciumW.NNA$grp=="C","bmd1"],
         y = calciumW.NNA[calciumW.NNA$grp=="P","bmd1"])
\end{lstlisting}

\phantomsection
\label{}
\begin{verbatim}

	F test to compare two variances

data:  calciumW.NNA[calciumW.NNA$grp == "C", "bmd1"] and calciumW.NNA[calciumW.NNA$grp == "P", "bmd1"]
F = 0.666, num df = 43, denom df = 46, p-value = 0.18
alternative hypothesis: true ratio of variances is not equal to 1
95 percent confidence interval:
 0.36801 1.21107
sample estimates:
ratio of variances 
           0.66559
\end{verbatim}

using an heteroschedastic linear regression with a parameter for the
residual standard deviation in the reference group (\(\sigma\)) and a
parameter for the ratio in standard deviation between the two groups
(\(k\)):
\begin{lstlisting}[language=r,numbers=none]
eVar2.lmm <- lmm(bmd1 ~ grp, structure = IND(~grp), data = calciumW.NNA)
coef(eVar2.lmm, effects = "variance")     
\end{lstlisting}

\phantomsection
\label{}
\begin{verbatim}
   sigma      k.C 
66.87928  0.81584
\end{verbatim}


This leads to the following modeled group-sepecific residual standard
deviations:
\begin{lstlisting}[language=r,numbers=none]
coef(eVar2.lmm, effects = "variance", transform.k = "sd")
\end{lstlisting}

\phantomsection
\label{}
\begin{verbatim}
sigma.P sigma.C 
 66.879  54.563
\end{verbatim}


Testing whether the \(k\) parameter is 1, i.e. its log is 0:
\begin{lstlisting}[language=r,numbers=none]
summary(anova(eVar2.lmm, effects = "variance"))
\end{lstlisting}

\phantomsection
\label{}
\begin{verbatim}
		Hypothesis-specific Wald test 

                 estimate    se   df lower upper p.value  
 variance: k.C=1    0.816 0.122 88.6 0.606 1.099   0.178  
 -------------------------------------------------------- 
  :  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1.
df: Satterthwaite approximation w.r.t. model-based se. 
se: based on the observed information (model-based). 
Back-transformation: k parameters with exp.
\end{verbatim}


leads to a similar p-value comapred to \texttt{var.test}. The estimate
differs as \texttt{anova} returns the ratio of the residual standard
deviations instead of the ratio of the residual variances. The later
can be obtained using:
\begin{lstlisting}[language=r,numbers=none]
summary(anova(eVar2.lmm, effects = "variance", transform.k = "logsquare"))
\end{lstlisting}

\phantomsection
\label{}
\begin{verbatim}
		Hypothesis-specific Wald test 

                 estimate  se   df lower upper p.value  
 variance: k.C=1    0.666 0.2 88.6 0.367 1.208   0.178  
 ------------------------------------------------------ 
  :  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1.
df: Satterthwaite approximation w.r.t. model-based se. 
se: based on the observed information (model-based). 
Back-transformation: k parameters with exp.
\end{verbatim}


closely matching the output of \texttt{var.test}. This test is the special
case of the Bartlett test:
\begin{lstlisting}[language=r,numbers=none]
bartlett.test(bmd1 ~ grp, data = calciumW.NNA)
\end{lstlisting}

\phantomsection
\label{}
\begin{verbatim}

	Bartlett test of homogeneity of variances

data:  bmd1 by grp
Bartlett's K-squared = 1.8, df = 1, p-value = 0.18
\end{verbatim}


which generalizes to more than two variances:
\begin{lstlisting}[language=r,numbers=none]
bartlett.test(age ~ sex.group,
              data = transform(abetaW.NNA, sex.group = paste0(sex,group)))
\end{lstlisting}

\phantomsection
\label{}
\begin{verbatim}

	Bartlett test of homogeneity of variances

data:  age by sex.group
Bartlett's K-squared = 1.68, df = 3, p-value = 0.64
\end{verbatim}


An F-test from the corresponding heteroschedastic linear regression
leads to the same results:
\begin{lstlisting}[language=r,numbers=none]
eVar4.lmm <- lmm(age ~ sex.group, structure = IND(~sex.group),
                 data = transform(abetaW.NNA, sex.group = paste0(sex,group)))
summary(anova(eVar4.lmm, effects = "variance"))
\end{lstlisting}

\phantomsection
\label{}
\begin{verbatim}
		Wald F-test 

                       statistic       df p.value  
   variance: sex.group     0.566 (3,53.1)    0.64  
   ----------------------------------------------- 
    :  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1.
  df: Satterthwaite approximation w.r.t. model-based se. 
  Multiple testing adjustment: joint test.

		Hypothesis-specific Wald tests 

                     estimate    se   df lower upper p.value  
   variance: k.FHC=1    1.143 0.241 34.3 0.681 1.919   0.874  
             k.MBD=1     0.92 0.157 68.5 0.606 1.398   0.935  
             k.MHC=1    1.131  0.22 47.2 0.701 1.822   0.876  
   ---------------------------------------------------------- 
    :  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1.
  df: Satterthwaite approximation w.r.t. model-based se. 
  se: based on the observed information (model-based). 
  Multiple testing adjustment: max test (1e+05 samples).
  Back-transformation: k parameters with exp.
\end{verbatim}

Note that the test statistic of \texttt{anova} multiplied by its (numerator)
degree of freedom \texttt{0.566*3} leads to the test statistic of
\texttt{bartlett.test}. \newline \Warning when considering variance of time
instead of variance between groups the equivalence is typically lost
as \texttt{lmm} can account for within-subject correlation (argument
\texttt{structure} set to \texttt{UN}) while \texttt{bartlett.test} cannot.

\clearpage
\section*{References}
\label{sec:org7fe91c5}
\begingroup
\renewcommand{\section}[2]{}

\bibliographystyle{apalike}
\bibliography{bibliography}

\endgroup

\clearpage

\appendix
\titleformat{\section}
{\normalfont\Large\bfseries}{Appendix~\thesection}{1em}{}

\renewcommand{\thefigure}{\Alph{figure}}
\renewcommand{\thetable}{\Alph{table}}
\renewcommand{\theequation}{\Alph{equation}}

\setcounter{figure}{0}    
\setcounter{table}{0}    
\setcounter{equation}{0}    
\end{document}
