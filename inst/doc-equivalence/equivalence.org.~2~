#+TITLE: Comparison with traditional tests and other R packages
#+Author: Brice Ozenne
#+BEGIN_SRC R :exports none :results silent :session *R* :cache no
options(width = 100, digits = 5)
if(system("whoami",intern=TRUE)=="bozenne"){  
  setwd("~/Documents/GitHub/LMMstar/inst/doc-equivalence/")
}else if(system("whoami",intern=TRUE)=="unicph\\hpl802"){  
  setwd("c:/Users/hpl802/Documents/Github/LMMstar/inst/doc-equivalence/")
}
library(ggpubr, quietly = TRUE, verbose = FALSE, warn.conflicts = FALSE)
#+END_SRC

This first part of this vignette make connexions between the output of
a linear mixed model and well-known test (t.test, ANCOVA,
Pearson's correlation). The second part of the vignette make connexion with other
\Rlogo packages.

* Illustrative dataset

We will illustrate the connexion using the gastricbypass dataset. The
long format can be imported using:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
data(gastricbypassL, package = "LMMstar")
head(gastricbypassL)
#+END_SRC

#+RESULTS:
: id visit time weight glucagonAUC
: 1  1     1  -13  127.2      20.690
: 2  2     1  -13  165.2      49.922
: 3  3     1  -13  109.7      42.434
: 4  4     1  -13  146.2      27.517
: 5  5     1  -13  113.1      29.151
: 6  6     1  -13  158.8      42.700

and add an (artificial) group variable:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
gastricbypassL$group <- factor(as.numeric(gastricbypassL$id)%%2)
#+END_SRC

#+RESULTS:

The corresponding wide format is
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
data(gastricbypassW, package = "LMMstar")
gastricbypassW$group <- factor(as.numeric(gastricbypassW$id)%%2)
head(gastricbypassW)
#+END_SRC

#+RESULTS:
: id weight1 weight2 weight3 weight4 glucagonAUC1 glucagonAUC2 glucagonAUC3 glucagonAUC4 group
: 1  1   127.2   120.7   115.5   108.1       20.690       20.535       92.600       43.434     1
: 2  2   165.2   153.4   149.2   132.0       49.922       58.513       49.633       35.747     0
: 3  3   109.7   101.6    97.7    87.1       42.434       25.770       91.240       83.137     1
: 4  4   146.2   142.4   136.7   123.0       27.517       27.552       59.360       21.371     0
: 5  5   113.1   105.6    99.9    87.7       29.151           NA       86.859       57.970     1
: 6  6   158.8   143.6   134.6   108.7       42.700       31.616       53.408       37.636     0

\clearpage


* Equivalence with other statistical methods
** Welch two sample t-test

A two sample t-test:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
with(gastricbypassW, t.test(x = weight4[group=="1"], y = weight4[group=="0"]))
#+END_SRC

#+RESULTS:
#+begin_example

	Welch Two Sample t-test

data:  weight4[group == "1"] and weight4[group == "0"]
t = -0.591, df = 17.7, p-value = 0.56
alternative hypothesis: true difference in means is not equal to 0
95 percent confidence interval:
 -20.916  11.736
sample estimates:
mean of x mean of y 
   100.07    104.66
#+end_example

is equivalent to an independent covariance pattern with a different
parameter for the residual variance in each group:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
e.ttest4 <- lmm(weight4 ~ group, structure = IND(~group), 
               data = gastricbypassW, trace = FALSE)
model.tables(e.ttest4, effects = "all")
#+END_SRC

#+RESULTS:
: estimate      se      df     lower    upper    p.value
: (Intercept) 104.6600 5.10447  9.0018  93.11324 116.2068 7.2710e-09
: group1       -4.5900 7.76067 17.6824 -20.91558  11.7356 5.6171e-01
: sigma        16.1417 3.80465  9.0018   9.47095  27.5111         NA
: k.1           1.1452 0.38174 18.0036   0.56853   2.3069 6.8896e-01


\clearpage

** Paired t-test

With complete data, a paired t-test:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
t.test(gastricbypassW$weight4, gastricbypassW$weight1, paired = TRUE)
#+END_SRC

#+RESULTS:
#+begin_example

	Paired t-test

data:  gastricbypassW$weight4 and gastricbypassW$weight1
t = -17.2, df = 19, p-value = 5e-13
alternative hypothesis: true mean difference is not equal to 0
95 percent confidence interval:
 -29.848 -23.362
sample estimates:
mean difference 
        -26.605
#+end_example

is equivalent to a LMM with an unstructured covariate pattern:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
e.lmm2tt <- lmm(weight ~ visit, repetition = ~visit|id, structure = "UN",
                data = gastricbypassL)
model.tables(e.lmm2tt)["visit4",,drop=FALSE]
#+END_SRC

#+RESULTS:
:        estimate     se     df   lower   upper    p.value
: visit4  -26.605 1.5494 18.964 -29.848 -23.362 5.1692e-13

\clearpage

** Welch two sample t-test on the change

With complete data, a two sample t-test comparing the change from baseline:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
gastricbypassW.0 <- gastricbypassW[gastricbypassW$group==0,]
gastricbypassW.1 <- gastricbypassW[gastricbypassW$group==1,]
t.test(gastricbypassW.0$weight4-gastricbypassW.0$weight1,
       gastricbypassW.1$weight4-gastricbypassW.1$weight1)
#+END_SRC

#+RESULTS:
#+begin_example

	Welch Two Sample t-test

data:  gastricbypassW.0$weight4 - gastricbypassW.0$weight1 and gastricbypassW.1$weight4 - gastricbypassW.1$weight1
t = -2.11, df = 13, p-value = 0.055
alternative hypothesis: true difference in means is not equal to 0
95 percent confidence interval:
 -12.16771   0.14771
sample estimates:
mean of x mean of y 
   -29.61    -23.60
#+end_example

is equivalent to a LMM with a stratified unstructured covariate pattern:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
e.lmm2tt2 <- lmm(weight ~ visit*group, repetition = ~visit|id, structure = UN(~group),
                 data = gastricbypassL)
model.tables(e.lmm2tt2)["visit4:group1",,drop=FALSE]
#+END_SRC

#+RESULTS:
:               estimate     se     df    lower  upper p.value
: visit4:group1     6.01 2.8511 13.009 -0.14908 12.169   0.055

\clearpage

** Multiple Student's t-test


Multiple t-tests:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
e.ttest1 <- lmm(weight1 ~ group, structure = IND(~group), 
                data = gastricbypassW, trace = FALSE)
e.ttest2 <- lmm(weight2 ~ group, structure = IND(~group), 
                data = gastricbypassW, trace = FALSE)
e.ttest3 <- lmm(weight3 ~ group, structure = IND(~group), 
                data = gastricbypassW, trace = FALSE)
#+END_SRC

#+RESULTS:

can be adjusted for multiple comparison by first using the =anova=
function to specify the parameter of interest and combining the
results using =rbind=:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
e.mttest <- rbind(anova(e.ttest1, effects = "group=0"),
                  anova(e.ttest2, effects = "group=0"),
                  anova(e.ttest3, effects = "group=0"),
                  anova(e.ttest4, effects = "group=0"),
                  repetition = ~1|id)
model.tables(e.mttest, method = "bonferroni")
#+END_SRC

#+RESULTS:
: Fejl i rbind(deparse.level, ...) : 
:   Extra arguments should inherit from Wald_lmm. 
: 1: model.tables(e.mttest, method = "bonferroni")
: Fejl: objekt 'e.mttest' blev ikke fundet
: 1: rbind(anova(e.ttest1, effects = "group=0"), anova(e.ttest2, effects = "group=0"), 
:        anova(e.ttest3, effects = "group=0"), anova(e.ttest4, effects = "group=0"), 
:        repetition = ~1 | id)
: 2: rbind(deparse.level, ...)
: 3: stop("Extra arguments should inherit from Wald_lmm. \n") at rbind.R#151

\Warning efficient adjustment for multiple comparisons (like
="single-step"=) will not be valid as the correlation structure has
not be specified. To do so it is more conveniently to work with a the
long format:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
e.mttest2 <- mlmm(weight ~ group, structure = IND(~group),
                  data = gastricbypassL, trace = FALSE,
                  effects = "group1=0", by = "time", repetition = ~time|id)
model.tables(e.mttest2, method = "single-step2")
#+END_SRC

#+RESULTS:
:    by parameter estimate     se     df   lower   upper p.value
: 1 -13    group1   -10.60 8.9717 17.965 -30.989  9.7893 0.31768
: 2  -1    group1    -9.50 8.3951 17.985 -28.579  9.5789 0.34123
: 3   1    group1    -8.92 8.1295 17.959 -27.395  9.5551 0.35785
: 4  13    group1    -4.59 7.7607 17.682 -22.227 13.0470 0.66473

or call the dedicated function =mt.test=:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
mt.test(weight1+weight2+weight3+weight4~group, data = gastricbypassW)
#+END_SRC

#+RESULTS:
:        by parameter estimate     se     df   lower   upper p.value
: 1 weight1     group   -10.60 8.9717 17.965 -30.976  9.7758 0.31870
: 2 weight2     group    -9.50 8.3951 17.985 -28.566  9.5663 0.34115
: 3 weight3     group    -8.92 8.1295 17.959 -27.383  9.5429 0.35844
: 4 weight4     group    -4.59 7.7607 17.682 -22.215 13.0354 0.66272

\clearpage

** Linear regression on the change 

A widely spread approach to analyze longitudinal data is to reduce the
number of repetitions to 1 by working on the change and then apply
'usual' statistical methods. For instance one could compare the pre-
and post- operation values using:

#+BEGIN_SRC R :exports both :results output :session *R* :cache no
gastricbypassW$changeG41 <- gastricbypassW$glucagonAUC4-gastricbypassW$glucagonAUC1
e.change41 <- lm(changeG41 ~ weight1, data = gastricbypassW)
summary(e.change41)$coef
#+END_SRC

#+RESULTS:
:             Estimate Std. Error t value Pr(>|t|)
: (Intercept) 88.41370   41.01024  2.1559 0.044871
: weight1     -0.53331    0.31432 -1.6967 0.106975

This turns out to be equivalent to the following mixed model:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
gastricbypassL41 <- gastricbypassL[gastricbypassL$visit %in% c(1,4),]
gastricbypassL41$visit <- droplevels(gastricbypassL41$visit)
gastricbypassL41$weight1 <- gastricbypassW$weight1[gastricbypassL41$id]

e.lmm41 <- lmm(glucagonAUC ~ visit + visit*weight1,
               repetition =~ visit|id, structure = "UN",
               data = gastricbypassL41)
model.tables(e.lmm41)
#+END_SRC

#+RESULTS:
:                  estimate       se     df     lower     upper p.value
: (Intercept)    31.7805917 23.58747 18.003 -17.77425  81.33543 0.19458
: visit4         88.4137014 41.01024 18.001   2.25477 174.57264 0.04487
: weight1         0.0041566  0.18078 18.003  -0.37565   0.38396 0.98191
: visit4:weight1 -0.5333052  0.31432 18.001  -1.19366   0.12705 0.10697

This equivalence only holds as there is no missing data.
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
index.missing41 <- which(is.na(gastricbypassW$changeG41))
index.missing41
#+END_SRC

#+RESULTS:
: integer(0)

\clearpage

** Correlation between changes 

In some studies, one is interested in studying the relation between
two evolutions. Say weight and glucagon before and after the
operation:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
gastricbypassW$changeG41 <- gastricbypassW$glucagonAUC4-gastricbypassW$glucagonAUC1
gastricbypassW$changeW41 <- gastricbypassW$weight4-gastricbypassW$weight1
#+END_SRC

#+RESULTS:

\bigskip

One can evaluate their correlation:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
cor.test(gastricbypassW$changeW41, gastricbypassW$changeG41)
#+END_SRC

#+RESULTS:
#+begin_example

	Pearson's product-moment correlation

data:  gastricbypassW$changeW41 and gastricbypassW$changeG41
t = 1.89, df = 18, p-value = 0.075
alternative hypothesis: true correlation is not equal to 0
95 percent confidence interval:
 -0.043829  0.719624
sample estimates:
    cor 
0.40658
#+end_example

or regress one against the other:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
e2.change41 <- lm(changeG41 ~ changeW41, data = gastricbypassW)
summary(e2.change41)$coef
#+END_SRC

#+RESULTS:
:             Estimate Std. Error t value Pr(>|t|)
: (Intercept)  65.0794   24.83368  2.6206 0.017331
: changeW41     1.7082    0.90473  1.8881 0.075246

This problem can be recast using all measurement as outcomes:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
keep.col <- c("id","weight1","weight4","glucagonAUC1","glucagonAUC4")
gastricbypassL4 <- reshape(gastricbypassW[,keep.col], direction = "long",
                           idvar = "id", varying = 2:5, timevar = "type", v.names = "value")
gastricbypassL4$type <- factor(gastricbypassL4$type, labels = keep.col[-1])
gastricbypassL4 <- gastricbypassL4[order(gastricbypassL4$id),]
head(gastricbypassL4)
#+END_SRC

#+RESULTS:
:     id         type   value
: 1.1  1      weight1 127.200
: 1.2  1      weight4 108.100
: 1.3  1 glucagonAUC1  20.690
: 1.4  1 glucagonAUC4  43.434
: 2.1  2      weight1 165.200
: 2.2  2      weight4 132.000

fitting an unstructured mixed model:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
e.lmm4 <- lmm(value ~ type,
              repetition = ~type|id, structure = "UN",
              data = gastricbypassL4)
#+END_SRC

#+RESULTS:

extract the residual covariance matrix:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
sigma.lmm4 <- sigma(e.lmm4)
sigma.lmm4
#+END_SRC

#+RESULTS:
:                weight1 weight4 glucagonAUC1 glucagonAUC4
: weight1       410.8475  326.84       1.7077     -217.399
: weight4       326.8357  290.84     -24.6003     -161.696
: glucagonAUC1    1.7077  -24.60     241.7007      -81.649
: glucagonAUC4 -217.3994 -161.70     -81.6493      442.464

Deduce the residual covariance matrix for the change:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
Mcon <- cbind(c(-1,1,0,0),c(0,0,-1,1))
sigmeChange.lmm4 <- t(Mcon) %*% sigma.lmm4 %*% Mcon
dimnames(sigmeChange.lmm4) <- list(c("d.weight","d.glucagonAUC"),
                                   c("d.weight","d.glucagonAUC"))
sigmeChange.lmm4
#+END_SRC

#+RESULTS:
:               d.weight d.glucagonAUC
: d.weight        48.011        82.011
: d.glucagonAUC   82.011       847.464

and the corrrelation or covariance:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
cov2cor(sigmeChange.lmm4)[1,2]
sigmeChange.lmm4[1,2]/sigmeChange.lmm4[1,1]
#+END_SRC

#+RESULTS:
: [1] 0.40658
: [1] 1.7082

The uncertainty can be quantified using a delta method:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
estimate(e.lmm4, function(p){
  Sigma.change <- t(Mcon) %*% sigma(e.lmm4, p = p) %*% Mcon
  c(cor = cov2cor(Sigma.change)[1,2],
    beta = Sigma.change[1,2]/Sigma.change[1,1])
})
#+END_SRC

#+RESULTS:
:      estimate      se     df    lower  upper p.value
: cor   0.40658 0.19150 2.5925 -0.26078 1.0739 0.13791
: beta  1.70818 0.88073 2.6876 -1.28836 4.7047 0.15837

The standard errors and degrees of freedom do not match the univariate
analysis, suggesting poor small sample properties of this
technic.

\clearpage

* Equivalence with other R packages

** nlme package

The model class obtained with the =lmm= function overlaps the model
class of the =lme= and =gls= functions from the nlme package.
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
library(nlme)
#+END_SRC

#+RESULTS:

For instance, the compound symmetry is equivalent to =corCompSymm=
correlation structure, or to a random intercept model (when the within
subject correlation is positive):
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
eRI.lmm <- lmm(weight ~ visit*group, structure = "RE",
               data = gastricbypassL, repetition = ~visit|id)
eCS.gls <- gls(weight ~ visit*group, correlation = corCompSymm(form=~visit|id),
               data = gastricbypassL, na.action = na.omit)
eCS.lme <- lme(weight ~ visit*group, random = ~1|id,
               data = gastricbypassL, na.action = na.omit)
logLik(eRI.lmm)
logLik(eCS.lme)
logLik(eCS.gls)
#+END_SRC

#+RESULTS:
: [1] -236.21
: 'log Lik.' -236.21 (df=10)
: 'log Lik.' -236.21 (df=10)

The estimated random effect also match:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
range(ranef(eRI.lmm)-ranef(eCS.lme))
#+END_SRC

#+RESULTS:
: [1] -1.7303e-08  2.6979e-08

Unstructured residual covariance matrix can also be obtained with
=gls=:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
eUN.gls <- gls(glucagonAUC ~ visit*group,
               correlation = corSymm(form=~as.numeric(visit)|id),
               weights = varIdent(form=~1|visit),
               data = gastricbypassL, na.action = na.omit)
logLik(eUN.gls)
logLik(eUN.lmm)
#+END_SRC

#+RESULTS:
: 'log Lik.' -295.31 (df=18)
: [1] -295.31

\clearpage

** lme4 package

The model class obtained with the =lmm= function overlaps the model
class of the =lmer= function from the lme4 package.
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
library(lme4)
library(lmerTest)
#+END_SRC

#+RESULTS:

For instance, the compound symmetry is equivalent to a random
intercept model (when the within subject correlation is positive):
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
eRI.lmer <- lmer(weight ~ visit*group + (1|id),
                 data = gastricbypassL)
logLik(eRI.lmer)
logLik(eRI.lmm)
#+END_SRC

#+RESULTS:
: 'log Lik.' -236.21 (df=10)
: [1] -236.21

The estimated random effects match:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
range(ranef(eRI.lmm)-ranef(eRI.lmer)$id)
#+END_SRC

#+RESULTS:
: [1] -1.5513e-08  2.4171e-08

Nested random effects correspond to block unstructured:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
eNRI.lmm <- lmm(weight ~ visit*group, structure = RE(~(1|id/baseline)),
               data = gastricbypassL, repetition = ~visit|id)
eNRI.lmer <- lmer(weight ~ visit*group + (1|id/baseline),
                  data = gastricbypassL)
logLik(eNRI.lmer)
logLik(eNRI.lmm)
#+END_SRC

#+RESULTS:
: 'log Lik.' -234.97 (df=11)
: [1] -234.97

And the estimated random effects still match:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
eRanefNRI.lmm <- ranef(eNRI.lmm, format = "wide")
eRanefNRI.lmer <- ranef(eNRI.lmer)
## id
range(eRanefNRI.lmm$estimate-eRanefNRI.lmer$id)
## baseline
range(c(eRanefNRI.lmm$estimate.FALSE,eRanefNRI.lmm$estimate.TRUE)-ranef(eNRI.lmer)$`baseline:id`)
#+END_SRC

#+RESULTS:
: [1] -5.8317e-06  9.0913e-06
: [1] -8.5850e-05  7.8971e-05

\clearpage

An unstructure residual covariance matrix can also be obtained using
random slopes:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
eUN.lmer <- lmer(glucagonAUC ~ visit*group + (0 + visit|id),
                 data = gastricbypassL,
                 control = lmerControl(check.nobs.vs.nRE = "ignore"))
logLik(eUN.lmer)
logLik(eUN.lmm)
#+END_SRC

#+RESULTS:
: Warning message:
: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
:   Model failed to converge with max|grad| = 0.00203036 (tol = 0.002, component 1)
: 'log Lik.' -295.31 (df=19)
: [1] -295.31

The uncertainty is quantified in a slightly different way, e.g.:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
anova(eUN.lmm)
#+END_SRC

#+RESULTS:
: 		Multivariate Wald test 
: 
:                      F-statistic       df p.value   
:    mean: visit             5.803 (3,16.9) 0.00647 **
:        : group             3.926 (1,18.0) 0.06302  .
:        : visit:group       2.762 (3,17.3) 0.07332  .

is very similar but not identical to:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
## only the last line is comparable
anova(eUN.lmer)
#+END_SRC

#+RESULTS:
: Type III Analysis of Variance Table with Satterthwaite's method
:             Sum Sq Mean Sq NumDF DenDF F value  Pr(>F)    
: visit         1339     446     3  17.4   18.29 1.3e-05 ***
: group            5       5     1  18.1    0.22   0.647    
: visit:group    203      68     3  17.4    2.77   0.073 .  
: ---
: Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

It is also possible to fit cross-random effects such as:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
data("Penicillin")
eCRI.lmer <- lmer(diameter ~ 1 + (1|plate) + (1|sample), Penicillin)
logLik(eCRI.lmer)
#+END_SRC

#+RESULTS:
: 'log Lik.' -165.43 (df=4)


#+RESULTS:

using =lmm=:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
Penicillin$index <- paste(Penicillin$sample,Penicillin$plate,sep=".")
Penicillin$id <- 1

eCRI.lmm <- lmm(diameter ~ 1 + (1|plate) + (1|sample), data = Penicillin)
logLik(eCRI.lmm)
#+END_SRC

#+RESULTS:
: [1] -165.43

Despite being significantly slower, the loglikelihood and random
effect still match:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
range(ranef(eCRI.lmm)$estimate-rbind(ranef(eCRI.lmer)$plate,ranef(eCRI.lmer)$sample))
#+END_SRC

#+RESULTS:
: [1] -4.3812e-07  6.0172e-07

** mmrm package

The package =mmrm= is an alternative implementation of mixed models
specified via covariance structures:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
library(mmrm)
e.mmrm <- mmrm(
  formula = FEV1 ~ RACE + SEX + ARMCD * AVISIT + us(AVISIT | USUBJID),
  data = fev_data
)
#+END_SRC

#+RESULTS:

It leads nearly identical results compared to =lmm=:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
e.lmm <- lmm(
  formula = FEV1 ~ RACE + SEX + ARMCD * AVISIT,
  repetition = ~ AVISIT | USUBJID, structure = "UN",
  data = fev_data, type.information = "expected"
)
#+END_SRC
#+RESULTS:
: Warning message:
: In .lmmNormalizeData(as.data.frame(data)[unique(stats::na.omit(var.all))],  :
:     3 clusters have been removed.

#+BEGIN_SRC R :exports both :results output :session *R* :cache no
logLik(e.mmrm) - logLik(e.lmm)
range(coef(e.mmrm) - coef(e.lmm))
range(vcov(e.mmrm) - vcov(e.lmm))
#+END_SRC

#+RESULTS:
: [1] -2.5413e-06
: [1] -0.00018301  0.00016268
: [1] -0.00039710  0.00020479

The main differences are:
- =mmrm= uses the expected information matrix to quantify uncertainty
  instead of the observed information matrix.
- =mmrm= implements the Kenward and Roger method for computing the degrees of
  freedom and not only the Satterthwaite approximation
- =mmrm= implements different covariance patterns
- =mmrm= is faster and probably more memorry efficient
- =mmrm= has currently fewer post-processing methods (e.g. adjustment
  multiple comparisons when testing several model parameters). This
  being said, the latest version of the package (0.3.7) included
  several additional extractor of model feature so this may be
  improved in the future.

#+BEGIN_SRC R :exports none :results output :session *R* :cache no
set.seed(10)
dataS4 <- sampleRem(100, n.times = 4, format = "long")
dataS4$id.f <- as.factor(dataS4$id)
e.lmm1 <- lmm(Y ~ visit*X1 + X6, repetition = ~visit|id, data = dataS4)
e.lmm2 <- mmrm(Y ~ visit*X1 + X6 + us(visit|id.f), data = dataS4)
logLik(e.lmm1)
logLik(e.lmm2)
microbenchmark::microbenchmark(
                  lmm = lmm(Y ~ visit*X1 + X6, repetition = ~visit|id, data = dataS4),
                  lmm0 = lmm(Y ~ visit*X1 + X6, repetition = ~visit|id, data = dataS4, df = FALSE),
                  mmrm = mmrm(Y ~ visit*X1 + X6 + us(visit|id.f), data = dataS4),
                  times = 50
                )
#+END_SRC

#+RESULTS:
: [1] -760.3082
: [1] -760.3082
: Unit: milliseconds
:  expr      min       lq      mean   median       uq      max neval cld
:   lmm 143.3612 163.3131 186.89159 196.0709 200.6004 220.6009    50 a  
:  lmm0  59.5744  67.4667  78.11758  79.9020  85.0430 122.4184    50  b 
:  mmrm  27.9402  34.9598  36.14161  37.1766  38.4489  45.1623    50   c


#+BEGIN_SRC R :exports none :results output :session *R* :cache no
dataL3 <- sampleRem(5000, n.times = 3, format = "long")
dataL3$id.f <- as.factor(dataL3$id)
e.lmm1 <- lmm(Y ~ visit*X1 + X6, repetition = ~visit|id, data = dataL3)
e.lmm2 <- mmrm(Y ~ visit*X1 + X6 + us(visit|id.f), data = dataL3)
logLik(e.lmm1)
logLik(e.lmm2)
microbenchmark::microbenchmark(
                  lmm = lmm(Y ~ visit*X1 + X6, repetition = ~visit|id, data = dataL3),
                  lmm0 = lmm(Y ~ visit*X1 + X6, repetition = ~visit|id, data = dataL3, df = FALSE),
                  mmrm = mmrm(Y ~ visit*X1 + X6 + us(visit|id.f), data = dataL3),
                  times = 20
                )
#+END_SRC

#+RESULTS:
: [1] -29929.47
: [1] -29929.47
: Unit: milliseconds
:  expr      min       lq     mean   median       uq       max neval cld
:   lmm 852.9435 878.4181 909.1854 892.9624 906.9167 1164.7141    20 a  
:  lmm0 563.8959 587.0884 637.6633 603.6918 633.1166  857.8971    20  b 
:  mmrm 669.4953 678.5426 704.9954 687.4764 703.5992  966.9066    20   c


#+BEGIN_SRC R :exports none :results output :session *R* :cache no
data <- sampleRem(5000, n.times = 4, format = "long")
data$id.f <- as.factor(data$id)
e.lmm1 <- lmm(Y ~ visit*X1 + X6, repetition = ~visit|id, data = data)
e.lmm2 <- mmrm(Y ~ visit*X1 + X6 + us(visit|id.f), data = data)
logLik(e.lmm1)
logLik(e.lmm2)
microbenchmark::microbenchmark(
                  lmm = lmm(Y ~ visit*X1 + X6, repetition = ~visit|id, data = data),
                  lmm0 = lmm(Y ~ visit*X1 + X6, repetition = ~visit|id, data = data, df = FALSE),
                  mmrm = mmrm(Y ~ visit*X1 + X6 + us(visit|id.f), data = data),
                  times = 20
                )
#+END_SRC

#+RESULTS:
: [1] -37769.25
: [1] -37769.25
: Unit: milliseconds
:  expr      min        lq      mean    median        uq      max neval cld
:   lmm 1144.132 1438.2282 1493.0397 1472.8144 1549.4191 1886.949    20  a 
:  lmm0  739.710  885.3336  907.0729  895.3615  914.7741 1176.493    20   b
:  mmrm 1260.906 1522.0530 1554.2281 1550.6463 1574.8884 1932.091    20  a

** emmeans package

To illustrate a key difference between the emmeans package and the
=effects.lmm= function we consider an informative and unbalanced group
variable:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
gastricbypassLB$group2 <- gastricbypassLB$weight1>150
#+END_SRC

Since =lmm=:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
eCS.lmm_2 <- lmm(glucagonAUC ~ visit*group2, repetition =~visit|id, structure = "CS", data = gastricbypassLB)
logLik(eCS.lmm_2)
#+END_SRC

#+RESULTS:
: [1] -315.2

we will use the equivalent with the random effect specification:

#+BEGIN_SRC R :exports both :results output :session *R* :cache no
eRI.lmer_2 <- lmer(glucagonAUC ~ visit*group2 + (1|id), data = gastricbypassLB)
logLik(eRI.lmer_2)
#+END_SRC

#+RESULTS:
: 'log Lik.' -315.2 (df=10)

While the two models are equivalent, the average outcome output by
=effects=:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
effects(eCS.lmm_2, variable = NULL)
#+END_SRC

#+RESULTS:
: 		Average counterfactual outcome
: 
:          estimate    se   df  lower  upper
:    (t=1)   32.317 4.426 64.3 23.476 41.158
:    (t=2)   29.653 4.535 65.2 20.598 38.709
:    (t=3)   77.308 4.535 65.1  68.25 86.366
:    (t=4)    51.95 4.426 64.3 43.109 60.791

substantially differ from the one of emmeans:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
library(emmeans)
emmeans(eRI.lmer_2, specs=~visit)
#+END_SRC

#+RESULTS:
#+begin_example
NOTE: Results may be misleading due to involvement in interactions
 visit emmean   SE   df lower.CL upper.CL
 1       33.6 5.53 64.2     22.6     44.7
 2       32.0 5.57 64.4     20.9     43.2
 3       70.0 5.57 64.4     58.9     81.1
 4       47.2 5.53 64.2     36.1     58.2

Results are averaged over the levels of: group2 
Degrees-of-freedom method: kenward-roger 
Confidence level used: 0.95
#+end_example

This is because when averaging over the level of a covariate, emmeans
considers /balanced groups/. In the example, the groups are not
balanced:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
table(gastricbypassLB$group2)/NROW(gastricbypassLB)
#+END_SRC

#+RESULTS:
: 
: FALSE  TRUE 
:   0.8   0.2

Based on the group and timepoint specific means:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
eCS.elmm_2 <- model.tables(effects(eCS.lmm_2, variable = "group2"))
eCS.elmm_2
#+END_SRC

#+RESULTS:
:   group2 visit estimate     se     df  lower  upper    p.value
: 1  FALSE     1   31.430 4.9484 64.349 21.545 41.314 2.4688e-08
: 2  FALSE     2   28.067 5.0996 65.383 17.884 38.251 6.6737e-07
: 3  FALSE     3   82.173 5.1008 65.211 71.986 92.359 0.0000e+00
: 4  FALSE     4   55.126 4.9484 64.349 45.241 65.010 0.0000e+00
: 5   TRUE     1   35.864 9.8967 64.349 16.095 55.633 5.7374e-04
: 6   TRUE     2   35.997 9.8967 64.349 16.228 55.766 5.4953e-04
: 7   TRUE     3   57.848 9.8967 64.349 38.079 77.617 1.8339e-07
: 8   TRUE     4   39.246 9.8967 64.349 19.477 59.015 1.8651e-04

We illustrate the difference:
- emmeans:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
0.5*eCS.elmm_2[eCS.elmm_2$group2==FALSE,"estimate"]+0.5*eCS.elmm_2[eCS.elmm_2$group2==TRUE,"estimate"]
#+END_SRC

#+RESULTS:
: [1] 33.647 32.032 70.010 47.186

- effects:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
0.8*eCS.elmm_2[eCS.elmm_2$group2==FALSE,"estimate"]+0.2*eCS.elmm_2[eCS.elmm_2$group2==TRUE,"estimate"]
#+END_SRC

#+RESULTS:
: [1] 32.317 29.653 77.308 51.950

The "emmeans" approach gives equal "weight" to the expected value of
both group:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
mu.group1 <-  as.double(coef(e.group)["(Intercept)"])
mu.group2 <-  as.double(coef(e.group)["(Intercept)"] + coef(e.group)["group2TRUE"])
p.group1 <- 14/20          ; p.group2 <- 6/20
c(emmeans = (mu.group1+mu.group2)/2, predict = mu.group1 * p.group1 + mu.group2 * p.group2)
#+END_SRC

#+RESULTS:
:  emmeans  predict 
: 4.450435 4.514352

\clearpage

** effectsize package (\(R^2\) or \(\eta^2\))

Partial \(\eta^2\) can be computed based on =lmer= using the effectsize package:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
library(effectsize)
eta_squared(eCS.lmer)
cat("\n")
#+END_SRC

#+RESULTS:
: # Effect Size for ANOVA (Type III)
: 
: Parameter   | Eta2 (partial) |       95% CI
: -------------------------------------------
: visit       |           0.64 | [0.50, 1.00]
: group       |           0.01 | [0.00, 1.00]
: visit:group |           0.19 | [0.03, 1.00]
: 
: - One-sided CIs: upper bound fixed at

and are approximately equal to what one can compute "manually":
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
eCS.Wald <- anova(eCS.lmm)$multivariate
eCS.Wald$df.num*eCS.Wald$statistic/(eCS.Wald$df.num*eCS.Wald$statistic+eCS.Wald$df.denom)
#+END_SRC

#+RESULTS:
: [1] 0.335374 0.033811 0.186290

The will not be true for heteroschedastic models:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
eUN.Wald <- anova(eUN.lmm)$multivariate
eUN.Wald$df.num*eUN.Wald$statistic/(eUN.Wald$df.num*eUN.Wald$statistic+eUN.Wald$df.denom)
#+END_SRC

#+RESULTS:
: [1] 0.50787 0.17905 0.32380

compared to:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
eta_squared(eUN.lmer)
cat("\n")
#+END_SRC

#+RESULTS:
: # Effect Size for ANOVA (Type III)
: 
: Parameter   | Eta2 (partial) |       95% CI
: -------------------------------------------
: visit       |           0.76 | [0.54, 1.00]
: group       |           0.01 | [0.00, 1.00]
: visit:group |           0.32 | [0.00, 1.00]
: 
: - One-sided CIs: upper bound fixed at

But in that case both may be misleading as the proportion of explained
variance is not clearly defined.

** MuMIn package (\(R^2\))

#+BEGIN_SRC R :exports both :results output :session *R* :cache no
library(MuMIn)
r.squaredGLMM(eCS.lmer)
cat("\n")
#+END_SRC

#+RESULTS:
:          R2m     R2c
: [1,] 0.51728 0.62222

To reproduce these R2, we extract from the random intercept model:
- the residual variance
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
sigmaW <- sigma(eCS.lmm)[1,1]-sigma(eCS.lmm)[1,2]
#+END_SRC

#+RESULTS:

- the variance of the random effect
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
sigmaB <- sigma(eCS.lmm)[1,2]
#+END_SRC

#+RESULTS:

- the variance of the fitted values:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
sigma2_XB <- var(fitted(eCS.lmm))
#+END_SRC

#+RESULTS:

and evalutae the ratios:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
c(R2m = sigma2_XB/(sigmaW + sigmaB + sigma2_XB),
  R2c = (sigma2_XB + sigmaB)/(sigmaW + sigmaB + sigma2_XB))
#+END_SRC

#+RESULTS:
:     R2m     R2c 
: 0.52549 0.62865

** EMAtools for Cohen's D :noexport:

Consider again the random intercept model:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
eRI.lmm <- lmm(weight ~ time + glucagon + (1|id), data = dfL)
eRI.lmer <- lmer(weight ~ time + glucagon + (1|id), data = dfL)
eRI.lme <- lme(weight ~ time + glucagon, random =~ 1|id, data = dfL)
#+END_SRC

#+RESULTS:
To estimate standardized effect sizes one can use the function
=lme.dscore= of the EMAtools packages that calculate Cohen's D:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
library(EMAtools)
## lme.dscore(eRI.lmer, type = "lme4") ## error
lme.dscore(weight ~ time + glucagon + (1|id), data = dfL, type = "lme4")
## lme.dscore(eRI.lme, type = "nlme") ## very simular but warning
#+END_SRC

#+RESULTS:
:                   t       df          d
: timeB1w   -7.230297 53.97873 -1.9682252
: timeA1w  -10.159167 54.20609 -2.7597138
: timeA3m  -24.888739 54.01461 -6.7729406
: glucagon   1.327685 54.45612  0.3598336

Internally the Cohen's D is evaluated as twice the test statistic
divided by the number of degrees of freedom:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
eRI.lmertable <- summary(eRI.lmer)$coefficient[-1,]
eRI.lmmtable <- model.tables(eRI.lmm, columns = add("statistic"))[-1,]

rbind(lmer = 2*eRI.lmertable[,"t value"]/sqrt(eRI.lmertable[,"df"]),
      lmm = 2*eRI.lmmtable$statistic/sqrt(eRI.lmmtable$df))
## small difference due to expected vs. observed information
#+END_SRC

#+RESULTS:
:        timeB1w   timeA1w   timeA3m  glucagon
: lmer -1.968225 -2.759714 -6.772941 0.3598336
: lmm  -1.968416 -2.765843 -6.776385 0.3614009

I am a bit surprised by the formula as to me an analogue of the
Cohen's d with a random intercept model would simply be the estimated
coefficient divided by the residual standard deviation:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
coef(eRI.lmm)["glucagon"]/sqrt(sigma(eRI.lmm)[1,1])
#+END_SRC

#+RESULTS:
:   glucagon 
: 0.04359717



#+BEGIN_SRC R :exports none :results output :session *R* :cache no
library(mvtnorm)
n <- 1e4
mu <- c(0,0,0)
sigma <- diag(0.5,3) + 0.5
dfW.sim <- rbind(data.frame(id = 1:n, group = "C", rmvnorm(n, mean = mu, sigma = sigma)),
                 data.frame(id = n+(1:n), group = "T", rmvnorm(n, mean = mu+1, sigma = sigma))
                 )
dfL.sim <- reshape(dfW.sim, direction = "long", idvar = "id",
                   timevar = "time", times = paste0("X",1:3),
                   varying = paste0("X",1:3), v.names = "value")
lme.dscore(value ~ group + (1|id), data = dfL.sim, type = "lme4")
eSim.lmer <- lmer(value ~ group + (1|id), data = dfL.sim)

eSim.lmm <- lmm(value ~ group + (1|id), data = dfL.sim)
coef(eSim.lmm)["groupT"]/sqrt(sigma(eSim.lmm)[1,1])

1/c(sqrt(1),sqrt(0.5))
#+END_SRC

#+RESULTS:
:               t    df        d
: groupT 86.16901 19998 1.218675
:   groupT 
: 1.408396
:    groupT 
: 0.9952911
: [1] 1.000000 1.414214


** stats package (partial residuals)

The function =residuals.lm= can be used to extract partial residuals
from =lm= objects. For instance:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
gastricbypassW$group <- as.factor(as.numeric(gastricbypassW$id)%%2)
eIID.lm <- lm(weight4 ~ group + weight1, data = gastricbypassW)
pRes.lm <- residuals(eIID.lm, type = "partial")
head(pRes.lm)
#+END_SRC

#+RESULTS:
:       group  weight1
: 1   7.19282   3.6648
: 2  -0.20504  31.7052
: 3   0.60631 -17.3352
: 4   6.44389  22.7052
: 5  -1.59403 -16.7352
: 6 -18.23382   8.4052

Those generally differ (by a constant) from the one provided by
=residuals.lmm=:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
eIID.lmm <- lmm(weight4 ~ group + weight1, data = gastricbypassW)
(residuals(eIID.lmm, type = "partial", variable = "group") - pRes.lm[,"group"])
(residuals(eIID.lmm, type = "partial", variable = "weight1") - pRes.lm[,"weight1"])
#+END_SRC

#+RESULTS:
:      1      2      3      4      5      6      7      8      9     10     11     12     13     14 
: 2.0702 2.0702 2.0702 2.0702 2.0702 2.0702 2.0702 2.0702 2.0702 2.0702 2.0702 2.0702 2.0702 2.0702 
:     15     16     17     18     19     20 
: 2.0702 2.0702 2.0702 2.0702 2.0702 2.0702
:      1      2      3      4      5      6      7      8      9     10     11     12     13     14 
: 106.22 106.22 106.22 106.22 106.22 106.22 106.22 106.22 106.22 106.22 106.22 106.22 106.22 106.22 
:     15     16     17     18     19     20 
: 106.22 106.22 106.22 106.22 106.22 106.22

Indeed, =residuals.lm= centers the design matrix of the variable
relative to which the partial residuals are computed:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
coef(eIID.lm)["group1"] * mean(gastricbypassW$group=="1")
coef(eIID.lm)["weight1"] * mean(gastricbypassW$weight1)
#+END_SRC

#+RESULTS:
: group1 
: 2.0702
: weight1 
:  106.22

For continuous variable with a linear effect, these residuals can be
obtained by setting the =type= argument to ="partial-center"=:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
(residuals(eIID.lmm, type = "partial-center", variable = "weight1") - pRes.lm[,"weight1"])
#+END_SRC

#+RESULTS:
:           1           2           3           4           5           6           7           8 
:  1.7675e-13  6.7502e-14 -6.3949e-14  5.6843e-14 -3.9080e-14  8.1712e-14 -3.7303e-14  5.9508e-14 
:           9          10          11          12          13          14          15          16 
: -4.2633e-14  4.4409e-14 -2.9310e-14  5.5123e-14 -4.6185e-14  4.4409e-14 -4.2633e-14  4.6185e-14 
:          17          18          19          20 
: -3.9968e-14  5.3291e-14 -1.4211e-14  3.5527e-14

\Warning When evaluating the partial residuals relative to categorical
variables, interactions, or non-linear terms, the output obtained with
=partial-center= will not match the one of =residuals.lm=. Indeed
=partial-center= will, when numeric, center the original variable
whereas =residuals.lm= will center the column relative to the
coefficient in the design matrix.



* References
:PROPERTIES:
:UNNUMBERED: t
:END:

#+BEGIN_EXPORT latex
\begingroup
\renewcommand{\section}[2]{}
#+END_EXPORT

bibliographystyle:apalike
[[bibliography:bibliography.bib]]

#+BEGIN_EXPORT latex
\endgroup
#+END_EXPORT

\clearpage

#+BEGIN_EXPORT LaTeX
\appendix
\titleformat{\section}
{\normalfont\Large\bfseries}{Appendix~\thesection}{1em}{}

\renewcommand{\thefigure}{\Alph{figure}}
\renewcommand{\thetable}{\Alph{table}}
\renewcommand{\theequation}{\Alph{equation}}

\setcounter{figure}{0}    
\setcounter{table}{0}    
\setcounter{equation}{0}    
#+END_EXPORT

* CONFIG                                                           :noexport:
#+LANGUAGE:  en
#+LaTeX_CLASS: org-article
#+LaTeX_CLASS_OPTIONS: [12pt]
#+OPTIONS:   title:t author:t toc:nil todo:nil
#+OPTIONS:   H:3 num:t 
#+OPTIONS:   TeX:t LaTeX:t
** Display of the document
# ## space between lines
#+LATEX_HEADER: \RequirePackage{setspace} % to modify the space between lines - incompatible with footnote in beamer
#+LaTeX_HEADER:\renewcommand{\baselinestretch}{1.1}
# ## margins
#+LaTeX_HEADER: \geometry{a4paper, left=10mm, right=10mm, top=10mm}
# ## personalize the prefix in the name of the sections
#+LaTeX_HEADER: \usepackage{titlesec}
# ## fix bug in titlesec version
# ##  https://tex.stackexchange.com/questions/299969/titlesec-loss-of-section-numbering-with-the-new-update-2016-03-15
#+LaTeX_HEADER: \usepackage{etoolbox}
#+LaTeX_HEADER: 
#+LaTeX_HEADER: \makeatletter
#+LaTeX_HEADER: \patchcmd{\ttlh@hang}{\parindent\z@}{\parindent\z@\leavevmode}{}{}
#+LaTeX_HEADER: \patchcmd{\ttlh@hang}{\noindent}{}{}{}
#+LaTeX_HEADER: \makeatother
** Color
# ## define new colors
#+LATEX_HEADER: \RequirePackage{colortbl} % arrayrulecolor to mix colors
#+LaTeX_HEADER: \definecolor{myorange}{rgb}{1,0.2,0}
#+LaTeX_HEADER: \definecolor{mypurple}{rgb}{0.7,0,8}
#+LaTeX_HEADER: \definecolor{mycyan}{rgb}{0,0.6,0.6}
#+LaTeX_HEADER: \newcommand{\lightblue}{blue!50!white}
#+LaTeX_HEADER: \newcommand{\darkblue}{blue!80!black}
#+LaTeX_HEADER: \newcommand{\darkgreen}{green!50!black}
#+LaTeX_HEADER: \newcommand{\darkred}{red!50!black}
#+LaTeX_HEADER: \definecolor{gray}{gray}{0.5}
# ## change the color of the links
#+LaTeX_HEADER: \hypersetup{
#+LaTeX_HEADER:  citecolor=[rgb]{0,0.5,0},
#+LaTeX_HEADER:  urlcolor=[rgb]{0,0,0.5},
#+LaTeX_HEADER:  linkcolor=[rgb]{0,0,0.5},
#+LaTeX_HEADER: }
** Font
# https://tex.stackexchange.com/questions/25249/how-do-i-use-a-particular-font-for-a-small-section-of-text-in-my-document
#+LaTeX_HEADER: \newenvironment{note}{\small \color{gray}\fontfamily{lmtt}\selectfont}{\par}
#+LaTeX_HEADER: \newenvironment{activity}{\color{orange}\fontfamily{qzc}\selectfont}{\par}
** Symbols
# ## valid and cross symbols
#+LaTeX_HEADER: \RequirePackage{pifont}
#+LaTeX_HEADER: \RequirePackage{relsize}
#+LaTeX_HEADER: \newcommand{\Cross}{{\raisebox{-0.5ex}%
#+LaTeX_HEADER:		{\relsize{1.5}\ding{56}}}\hspace{1pt} }
#+LaTeX_HEADER: \newcommand{\Valid}{{\raisebox{-0.5ex}%
#+LaTeX_HEADER:		{\relsize{1.5}\ding{52}}}\hspace{1pt} }
#+LaTeX_HEADER: \newcommand{\CrossR}{ \textcolor{red}{\Cross} }
#+LaTeX_HEADER: \newcommand{\ValidV}{ \textcolor{green}{\Valid} }
# ## warning symbol
#+LaTeX_HEADER: \usepackage{stackengine}
#+LaTeX_HEADER: \usepackage{scalerel}
#+LaTeX_HEADER: \newcommand\Warning[1][3ex]{%
#+LaTeX_HEADER:   \renewcommand\stacktype{L}%
#+LaTeX_HEADER:   \scaleto{\stackon[1.3pt]{\color{red}$\triangle$}{\tiny\bfseries !}}{#1}%
#+LaTeX_HEADER:   \xspace
#+LaTeX_HEADER: }

** Code
:PROPERTIES:
:ID: 2ec77c4b-f83d-4612-9a89-a96ba1b7bf70
:END:
# Documentation at https://org-babel.readthedocs.io/en/latest/header-args/#results
# :tangle (yes/no/filename) extract source code with org-babel-tangle-file, see http://orgmode.org/manual/Extracting-source-code.html 
# :cache (yes/no)
# :eval (yes/no/never)
# :results (value/output/silent/graphics/raw/latex)
# :export (code/results/none/both)
#+PROPERTY: header-args :session *R* :tangle yes :cache no ## extra argument need to be on the same line as :session *R*
# Code display:
#+LATEX_HEADER: \RequirePackage{fancyvrb}
#+LATEX_HEADER: \DefineVerbatimEnvironment{verbatim}{Verbatim}{fontsize=\small,formatcom = {\color[rgb]{0.5,0,0}}}
# ## change font size input (global change)
# ## doc: https://ctan.math.illinois.edu/macros/latex/contrib/listings/listings.pdf
# #+LATEX_HEADER: \newskip kipamount    kipamount =6pt plus 0pt minus 6pt
# #+LATEX_HEADER: \lstdefinestyle{code-tiny}{basicstyle=\ttfamily\tiny, aboveskip =  kipamount, belowskip =  kipamount}
# #+LATEX_HEADER: \lstset{style=code-tiny}
# ## change font size input (local change, put just before BEGIN_SRC)
# ## #+ATTR_LATEX: :options basicstyle=\ttfamily\scriptsize
# ## change font size output (global change)
# ## \RecustomVerbatimEnvironment{verbatim}{Verbatim}{fontsize=\tiny,formatcom = {\color[rgb]{0.5,0,0}}}
** Rlogo
#+LATEX_HEADER:\definecolor{grayR}{HTML}{8A8990}
#+LATEX_HEADER:\definecolor{grayL}{HTML}{C4C7C9}
#+LATEX_HEADER:\definecolor{blueM}{HTML}{1F63B5}   
#+LATEX_HEADER: \newcommand{\Rlogo}[1][0.07]{
#+LATEX_HEADER: \begin{tikzpicture}[scale=#1]
#+LATEX_HEADER: \shade [right color=grayR,left color=grayL,shading angle=60] 
#+LATEX_HEADER: (-3.55,0.3) .. controls (-3.55,1.75) 
#+LATEX_HEADER: and (-1.9,2.7) .. (0,2.7) .. controls (2.05,2.7)  
#+LATEX_HEADER: and (3.5,1.6) .. (3.5,0.3) .. controls (3.5,-1.2) 
#+LATEX_HEADER: and (1.55,-2) .. (0,-2) .. controls (-2.3,-2) 
#+LATEX_HEADER: and (-3.55,-0.75) .. cycle;
#+LATEX_HEADER: 
#+LATEX_HEADER: \fill[white] 
#+LATEX_HEADER: (-2.15,0.2) .. controls (-2.15,1.2) 
#+LATEX_HEADER: and (-0.7,1.8) .. (0.5,1.8) .. controls (2.2,1.8) 
#+LATEX_HEADER: and (3.1,1.2) .. (3.1,0.2) .. controls (3.1,-0.75) 
#+LATEX_HEADER: and (2.4,-1.45) .. (0.5,-1.45) .. controls (-1.1,-1.45) 
#+LATEX_HEADER: and (-2.15,-0.7) .. cycle;
#+LATEX_HEADER: 
#+LATEX_HEADER: \fill[blueM] 
#+LATEX_HEADER: (1.75,1.25) -- (-0.65,1.25) -- (-0.65,-2.75) -- (0.55,-2.75) -- (0.55,-1.15) -- 
#+LATEX_HEADER: (0.95,-1.15)  .. controls (1.15,-1.15) 
#+LATEX_HEADER: and (1.5,-1.9) .. (1.9,-2.75) -- (3.25,-2.75)  .. controls (2.2,-1) 
#+LATEX_HEADER: and (2.5,-1.2) .. (1.8,-0.95) .. controls (2.6,-0.9) 
#+LATEX_HEADER: and (2.85,-0.35) .. (2.85,0.2) .. controls (2.85,0.7) 
#+LATEX_HEADER: and (2.5,1.2) .. cycle;
#+LATEX_HEADER: 
#+LATEX_HEADER: \fill[white]  (1.4,0.4) -- (0.55,0.4) -- (0.55,-0.3) -- (1.4,-0.3).. controls (1.75,-0.3) 
#+LATEX_HEADER: and (1.75,0.4) .. cycle;
#+LATEX_HEADER: 
#+LATEX_HEADER: \end{tikzpicture}
#+LATEX_HEADER: }
** Image and graphs
#+LATEX_HEADER: \RequirePackage{epstopdf} % to be able to convert .eps to .pdf image files
#+LATEX_HEADER: \RequirePackage{capt-of} % 
#+LATEX_HEADER: \RequirePackage{caption} % newlines in graphics
#+LaTeX_HEADER: \RequirePackage{tikz-cd} % graph
# ## https://tools.ietf.org/doc/texlive-doc/latex/tikz-cd/tikz-cd-doc.pdf
** Table
#+LATEX_HEADER: \RequirePackage{booktabs} % for nice lines in table (e.g. toprule, bottomrule, midrule, cmidrule)
** Inline latex
# @@latex:any arbitrary LaTeX code@@
** Algorithm
#+LATEX_HEADER: \RequirePackage{amsmath}
#+LATEX_HEADER: \RequirePackage{algorithm}
#+LATEX_HEADER: \RequirePackage[noend]{algpseudocode}
** Math
#+LATEX_HEADER: \RequirePackage{dsfont}
#+LATEX_HEADER: \RequirePackage{amsmath,stmaryrd,graphicx}
#+LATEX_HEADER: \RequirePackage{prodint} % product integral symbol (\PRODI)
# ## lemma
# #+LaTeX_HEADER: \RequirePackage{amsthm}
# #+LaTeX_HEADER: \newtheorem{theorem}{Theorem}
# #+LaTeX_HEADER: \newtheorem{lemma}[theorem]{Lemma}
*** Template for shortcut
#+LATEX_HEADER: \usepackage{ifthen}
#+LATEX_HEADER: \usepackage{xifthen}
#+LATEX_HEADER: \usepackage{xargs}
#+LATEX_HEADER: \usepackage{xspace}
#+LATEX_HEADER: \newcommand\defOperator[7]{%
#+LATEX_HEADER:	\ifthenelse{\isempty{#2}}{
#+LATEX_HEADER:		\ifthenelse{\isempty{#1}}{#7{#3}#4}{#7{#3}#4 \left#5 #1 \right#6}
#+LATEX_HEADER:	}{
#+LATEX_HEADER:	\ifthenelse{\isempty{#1}}{#7{#3}#4_{#2}}{#7{#3}#4_{#1}\left#5 #2 \right#6}
#+LATEX_HEADER: }
#+LATEX_HEADER: }
#+LATEX_HEADER: \newcommand\defUOperator[5]{%
#+LATEX_HEADER: \ifthenelse{\isempty{#1}}{
#+LATEX_HEADER:		#5\left#3 #2 \right#4
#+LATEX_HEADER: }{
#+LATEX_HEADER:	\ifthenelse{\isempty{#2}}{\underset{#1}{\operatornamewithlimits{#5}}}{
#+LATEX_HEADER:		\underset{#1}{\operatornamewithlimits{#5}}\left#3 #2 \right#4}
#+LATEX_HEADER: }
#+LATEX_HEADER: }
#+LATEX_HEADER: \newcommand{\defBoldVar}[2]{	
#+LATEX_HEADER:	\ifthenelse{\equal{#2}{T}}{\boldsymbol{#1}}{\mathbf{#1}}
#+LATEX_HEADER: }
**** Probability
#+LATEX_HEADER: \newcommandx\Esp[2][1=,2=]{\defOperator{#1}{#2}{E}{}{\lbrack}{\rbrack}{\mathbb}}
#+LATEX_HEADER: \newcommandx\Prob[2][1=,2=]{\defOperator{#1}{#2}{P}{}{\lbrack}{\rbrack}{\mathbb}}
#+LATEX_HEADER: \newcommandx\Qrob[2][1=,2=]{\defOperator{#1}{#2}{Q}{}{\lbrack}{\rbrack}{\mathbb}}
#+LATEX_HEADER: \newcommandx\Var[2][1=,2=]{\defOperator{#1}{#2}{V}{ar}{\lbrack}{\rbrack}{\mathbb}}
#+LATEX_HEADER: \newcommandx\Cov[2][1=,2=]{\defOperator{#1}{#2}{C}{ov}{\lbrack}{\rbrack}{\mathbb}}
#+LATEX_HEADER: \newcommandx\Binom[2][1=,2=]{\defOperator{#1}{#2}{B}{}{(}{)}{\mathcal}}
#+LATEX_HEADER: \newcommandx\Gaus[2][1=,2=]{\defOperator{#1}{#2}{N}{}{(}{)}{\mathcal}}
#+LATEX_HEADER: \newcommandx\Wishart[2][1=,2=]{\defOperator{#1}{#2}{W}{ishart}{(}{)}{\mathcal}}
#+LATEX_HEADER: \newcommandx\Likelihood[2][1=,2=]{\defOperator{#1}{#2}{L}{}{(}{)}{\mathcal}}
#+LATEX_HEADER: \newcommandx\logLikelihood[2][1=,2=]{\defOperator{#1}{#2}{\ell}{}{(}{)}{}}
#+LATEX_HEADER: \newcommandx\Information[2][1=,2=]{\defOperator{#1}{#2}{I}{}{(}{)}{\mathcal}}
#+LATEX_HEADER: \newcommandx\Hessian[2][1=,2=]{\defOperator{#1}{#2}{H}{}{(}{)}{\mathcal}}
#+LATEX_HEADER: \newcommandx\Score[2][1=,2=]{\defOperator{#1}{#2}{S}{}{(}{)}{\mathcal}}
**** Operators
#+LATEX_HEADER: \newcommandx\Vois[2][1=,2=]{\defOperator{#1}{#2}{V}{}{(}{)}{\mathcal}}
#+LATEX_HEADER: \newcommandx\IF[2][1=,2=]{\defOperator{#1}{#2}{IF}{}{(}{)}{\mathcal}}
#+LATEX_HEADER: \newcommandx\Ind[1][1=]{\defOperator{}{#1}{1}{}{(}{)}{\mathds}}
#+LATEX_HEADER: \newcommandx\Max[2][1=,2=]{\defUOperator{#1}{#2}{(}{)}{min}}
#+LATEX_HEADER: \newcommandx\Min[2][1=,2=]{\defUOperator{#1}{#2}{(}{)}{max}}
#+LATEX_HEADER: \newcommandx\argMax[2][1=,2=]{\defUOperator{#1}{#2}{(}{)}{argmax}}
#+LATEX_HEADER: \newcommandx\argMin[2][1=,2=]{\defUOperator{#1}{#2}{(}{)}{argmin}}
#+LATEX_HEADER: \newcommandx\cvD[2][1=D,2=n \rightarrow \infty]{\xrightarrow[#2]{#1}}
#+LATEX_HEADER: \newcommandx\Hypothesis[2][1=,2=]{
#+LATEX_HEADER:         \ifthenelse{\isempty{#1}}{
#+LATEX_HEADER:         \mathcal{H}
#+LATEX_HEADER:         }{
#+LATEX_HEADER: 	\ifthenelse{\isempty{#2}}{
#+LATEX_HEADER: 		\mathcal{H}_{#1}
#+LATEX_HEADER: 	}{
#+LATEX_HEADER: 	\mathcal{H}^{(#2)}_{#1}
#+LATEX_HEADER:         }
#+LATEX_HEADER:         }
#+LATEX_HEADER: }
#+LATEX_HEADER: \newcommandx\dpartial[4][1=,2=,3=,4=\partial]{
#+LATEX_HEADER: 	\ifthenelse{\isempty{#3}}{
#+LATEX_HEADER: 		\frac{#4 #1}{#4 #2}
#+LATEX_HEADER: 	}{
#+LATEX_HEADER: 	\left.\frac{#4 #1}{#4 #2}\right\rvert_{#3}
#+LATEX_HEADER: }
#+LATEX_HEADER: }
#+LATEX_HEADER: \newcommandx\dTpartial[3][1=,2=,3=]{\dpartial[#1][#2][#3][d]}
#+LATEX_HEADER: \newcommandx\ddpartial[3][1=,2=,3=]{
#+LATEX_HEADER: 	\ifthenelse{\isempty{#3}}{
#+LATEX_HEADER: 		\frac{\partial^{2} #1}{\partial #2^2}
#+LATEX_HEADER: 	}{
#+LATEX_HEADER: 	\frac{\partial^2 #1}{\partial #2\partial #3}
#+LATEX_HEADER: }
#+LATEX_HEADER: } 
**** General math
#+LATEX_HEADER: \newcommand\Real{\mathbb{R}}
#+LATEX_HEADER: \newcommand\Rational{\mathbb{Q}}
#+LATEX_HEADER: \newcommand\Natural{\mathbb{N}}
#+LATEX_HEADER: \newcommand\trans[1]{{#1}^\intercal}%\newcommand\trans[1]{{\vphantom{#1}}^\top{#1}}
#+LATEX_HEADER: \newcommand{\independent}{\mathrel{\text{\scalebox{1.5}{$\perp\mkern-10mu\perp$}}}}
#+LaTeX_HEADER: \newcommand\half{\frac{1}{2}}
#+LaTeX_HEADER: \newcommand\normMax[1]{\left|\left|#1\right|\right|_{max}}
#+LaTeX_HEADER: \newcommand\normTwo[1]{\left|\left|#1\right|\right|_{2}}
#+LATEX_HEADER: \newcommand\Veta{\boldsymbol{\eta}}

** Notations

#+LaTeX_HEADER:\newcommand{\Model}{\mathcal{M}}
#+LaTeX_HEADER:\newcommand{\ModelHat}{\widehat{\mathcal{M}}}

#+LaTeX_HEADER:\newcommand{\param}{\Theta}
#+LaTeX_HEADER:\newcommand{\paramHat}{\widehat{\param}}
#+LaTeX_HEADER:\newcommand{\paramCon}{\widetilde{\param}}

#+LaTeX_HEADER:\newcommand{\Vparam}{\boldsymbol{\param}}
#+LaTeX_HEADER:\newcommand{\VparamT}{\Vparam_0}
#+LaTeX_HEADER:\newcommand{\VparamHat}{\boldsymbol{\paramHat}}
#+LaTeX_HEADER:\newcommand{\VparamCon}{\boldsymbol{\paramCon}}

#+LaTeX_HEADER:\newcommand{\X}{X}
#+LaTeX_HEADER:\newcommand{\x}{x}
#+LaTeX_HEADER:\newcommand{\VX}{\boldsymbol{X}}
#+LaTeX_HEADER:\newcommand{\Vx}{\boldsymbol{x}}

#+LaTeX_HEADER:\newcommand{\Y}{Y}
#+LaTeX_HEADER:\newcommand{\y}{y}
#+LaTeX_HEADER:\newcommand{\VY}{\boldsymbol{Y}}
#+LaTeX_HEADER:\newcommand{\Vy}{\boldsymbol{y}}
#+LaTeX_HEADER:\newcommand{\Vvarepsilon}{\boldsymbol{\varepsilon}}

#+LaTeX_HEADER:\newcommand{\Z}{Z}
#+LaTeX_HEADER:\newcommand{\z}{z}
#+LaTeX_HEADER:\newcommand{\VZ}{\boldsymbol{Z}}
#+LaTeX_HEADER:\newcommand{\Vz}{\boldsymbol{z}}

