#+TITLE: Overview of the package LMMstar
#+Author: Brice Ozenne
#+BEGIN_SRC R :exports none :results output :session *R* :cache no
options(width = 100)
if(system("whoami",intern=TRUE)=="bozenne"){  
  setwd("~/Documents/GitHub/LMMstar/inst/doc-software/")
}

#+END_SRC

#+RESULTS:

This vignette describes the main functionalities of the *LMMstar*
package. This package implements specific types of multivariate
Gaussian models mainly useful when having repeated observations over a
discrete variable (e.g. time, brain region, ...). Key assumptions are
that at the cluster level, observation are independent and identically
distributed and that the mean and variance are driven by independent
factors. In particular, in large samples the residuals do not have to
be normally distributed.

\bigskip

The *LMMstar* package contains four main functions:
- the function =lmm= is the main function of the package which fits
  multivariate Gaussian models. The user can interact with /lmm/
  objects using:
    + =anova= to test combinations of coefficients (Wald test or Likelihood ratio tests)
    + =coef= to extract the estimates.
    + =confint= to extract estimates, confidence intervals, and p.values.
    + =getVarCov= to extract the modeled residual variance covariance matrix.
    + =logLik= to output the log-likelihood of the estimated model.
    + =predict= to compute the conditional mean for new observations.
    + =residuals= to extract the observed residuals of the fitted model.
    + =summary= to obtain a summary of the results
- the =summarize= function to compute summary statistics stratified on a categorical variable (typically time).
- the =sampleRem= function to simulate longitudinal data.
- the =LMMstar.options= function enables the user to display the
  default values used in the *LMMstar* package. function. The function
  can also change the default values to better match the user needs.

\clearpage

Before going further we need to load the *LMMstar* package in the R
session:
#+BEGIN_SRC R  :results silent   :exports code  :session *R* :cache no
library(LMMstar)
#+END_SRC

To illustrate the functionalities of the package, we will use the
=veteran= dataset:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
data(gastricbypassL)
head(gastricbypassL)
#+END_SRC

#+RESULTS:
:   id visit                    time weight glucagon
: 1  1     1 3 months before surgery  127.2  5032.50
: 2  2     1 3 months before surgery  165.2 12142.50
: 3  3     1 3 months before surgery  109.7 10321.35
: 4  4     1 3 months before surgery  146.2  6693.00
: 5  5     1 3 months before surgery  113.1  7090.50
: 6  6     1 3 months before surgery  158.8 10386.00

See =?gastricbypassL= for a presentation of the database. We will use a shorter version of the time variable:
#+begin_src R :exports both :results output :session *R* :cache no
gastricbypassL$time <- factor(gastricbypassL$time,
                              levels = c("3 months before surgery", "1 week before surgery",
                                                            "1 week after surgery", "3 months after surgery" ),
                              labels = c("B3_months","B1_week","A1_week","A3_months"))
#+end_src
#+RESULTS:
and rescale the glucagon values
#+begin_src R :exports both :results output :session *R* :cache no
gastricbypassL$glucagon <- as.double(scale(gastricbypassL$glucagon))
#+end_src

#+RESULTS:

\bigskip

_Note:_ the *LMMstar* package is under active development. Newer
package versions may include additional functionalities and fix
previous bugs. The version of the package that is being is:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
utils::packageVersion("LMMstar")
#+END_SRC

#+RESULTS:
: [1] ‘0.2’

\clearpage

* Descriptive statistics
Mean, standard deviation, and other summary statistic can be computed
with respect to a categorical variable (typically time) using the
=summarize= function:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
sss <- summarize(weight+glucagon ~ time, data = gastricbypassL, na.rm = TRUE)
print(sss, digits = 3)
#+END_SRC

#+RESULTS:
:    outcome      time observed missing     mean     sd     min   median     max
: 1   weight B3_months       20       0 128.9700 20.269 100.900 123.1000 173.000
: 2   weight   B1_week       20       0 121.2400 18.910  95.700 114.5000 162.200
: 3   weight   A1_week       20       0 115.7000 18.275  89.900 110.6000 155.000
: 4   weight A3_months       20       0 102.3650 17.054  78.800  98.5000 148.000
: 5 glucagon B3_months       20       0  -0.4856  0.641  -1.395  -0.6679   1.030
: 6 glucagon   B1_week       19       1  -0.6064  0.558  -1.416  -0.7669   0.946
: 7 glucagon   A1_week       19       1   1.0569  1.044  -0.478   0.9408   3.267
: 8 glucagon A3_months       20       0   0.0576  0.760  -1.047   0.0319   2.124

\clearpage

* Multivariate Gaussian model
** Modeling tools
Fit a multivariate Gaussian model with *compound symmetry* structure:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
eCS.lmm <- lmm(weight ~ time + glucagon,
               structure = CS(~time|id),
               data = gastricbypassL)
eCS.lmm
#+END_SRC

#+RESULTS:
:   Multivariate Gaussian Model with a compound symmetry covariance matrix 
:  
: data           : 78 observations and distributed in 20 clusters 
: log-likelihood : -243.6005
: parameters     : 5 mean ((Intercept) timeB1_week timeA1_week timeA3_months glucagon) 
:                  1 variance (sigma) 
:                  1 correlation (Rho)


\noindent Fit a multivariate Gaussian model with *unstructured* covariance matrix:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
eUN.lmm <- lmm(weight ~ time + glucagon,
               structure = UN(~time|id),
               data = gastricbypassL)
eUN.lmm
#+END_SRC

#+RESULTS:
:   Multivariate Gaussian Model with an unstructured covariance matrix 
:  
: data           : 78 observations and distributed in 20 clusters 
: log-likelihood : -216.3189
: parameters     : 5 mean ((Intercept) timeB1_week timeA1_week timeA3_months glucagon) 
:                  4 variance (sigma k.B1_week k.A1_week k.A3_months) 
:                  6 correlation (cor(B1_week,B3_months) cor(A1_week,B3_months) cor(A3_months,B3_months) cor(A1_week,B1_week) cor(A3_months,B1_week) cor(A3_months,A1_week))

_Note:_ the calculation of the degrees of freedom, especially when
using the observed information can be quite slow. Setting the
arguments =df= to =FALSE= and =type.information= to ="expected"= when
calling =lmm= should lead to a more reasonnable computation time.

\clearpage

** Model output

The =summary= method can be used to display the main information
relative to the model fit:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
summary(eCS.lmm, ci = TRUE)
#+END_SRC

#+RESULTS:
#+begin_example
  Multivariate Gaussian Model with a compound symmetry covariance matrix 
  - fitted using Restricted Maximum Likelihood (REML) 
  - log-likelihood :-243.6005 (parameters: mean = 5, variance = 1, correlation = 1)
 
Dataset: gastricbypassL 
 - 20 clusters 
 - 78 observations were analyzed, 2 were excluded because of missing values 
 - 4 maximum number of observations per cluster 
 - levels of the categorical variables 
 - reference level: time=B3_months 
 
$time
          B1_week A1_week A3_months
B3_months       0       0         0
B1_week         1       0         0
A1_week         0       1         0
A3_months       0       0         1

Correlation structure: ~1 | id 
          B3_months B1_week A1_week A3_months
B3_months      1.00    0.97    0.97      0.97
B1_week        0.97    1.00    0.97      0.97
A1_week        0.97    0.97    1.00      0.97
A3_months      0.97    0.97    0.97      1.00

Variance structure: ~1 
      standard.deviation
sigma           18.84957

Mean structure: weight ~ time + glucagon 
              estimate    se     df   lower   upper p.value    
(Intercept)    129.369 4.226 20.224 120.561 120.561  <0.001 ***
timeB1_week     -7.619 1.054 54.431  -9.732  -9.732  <0.001 ***
timeA1_week    -14.495 1.428  53.73 -17.358 -17.358  <0.001 ***
timeA3_months  -27.051 1.087 54.286 -29.231 -29.231  <0.001 ***
glucagon         0.822  0.62 53.053  -0.422  -0.422   0.191    

The columns lower and upper correspond to the 95% confidence interval of the estimated coefficient
Note: p-values and confidence intervals are not adjusted for multiple comparisons
#+end_example

\clearpage

** Extract estimated coefficients
The value of the estimated coefficients can be output using =coef=:
#+begin_src R :exports both :results output :session *R* :cache no
coef(eCS.lmm)
#+end_src

#+RESULTS:
:   (Intercept)   timeB1_week   timeA1_week timeA3_months      glucagon    log(sigma)    atanh(Rho) 
:   129.3690995    -7.6194918   -14.4951323   -27.0514694     0.8217879     2.9364900     2.0911816

It is possible to apply specific transformation on the variance
coefficients, for instance to obtain the residual variance relative to
each outcome:
#+begin_src R :exports both :results output :session *R* :cache no
coef(eUN.lmm, effects = "variance", transform.k = "sd")
#+end_src

#+RESULTS:
: sigma:B3_months   sigma:B1_week   sigma:A1_week sigma:A3_months 
:        20.28080        19.04553        17.65479        16.76104

** Extract estimated residual variance-covariance structure

The method =getVarCov= can be used to output the covariance structure of the residuals:
#+begin_src R :exports both :results output :session *R* :cache no
getVarCov(eCS.lmm)
#+end_src

#+RESULTS:
:           B3_months  B1_week  A1_week A3_months
: B3_months  355.3062 344.6236 344.6236  344.6236
: B1_week    344.6236 355.3062 344.6236  344.6236
: A1_week    344.6236 344.6236 355.3062  344.6236
: A3_months  344.6236 344.6236 344.6236  355.3062

It can also be specific to an individual:
#+begin_src R :exports both :results output :session *R* :cache no
getVarCov(eCS.lmm, individual = 5)
#+end_src

#+RESULTS:
:           B3_months  A1_week A3_months
: B3_months  355.3062 344.6236  344.6236
: A1_week    344.6236 355.3062  344.6236
: A3_months  344.6236 344.6236  355.3062

\clearpage

** Model diagnostic
The method =residuals= can be used to output the normalized residuals in a wide format:
#+begin_src R :exports both :results output :session *R* :cache no
eCS.diag <- residuals(eCS.lmm, type.residual = "normalized", format = "wide")
#+end_src

#+RESULTS:

This can for instance be used to check the auto-correlation between the residuals:
#+begin_src R :exports both :results output :session *R* :cache no
cor(eCS.diag[,-1,drop=FALSE], use = "pairwise")
#+end_src
#+RESULTS:
:           B3_months   B1_week   A1_week A3_months
: B3_months 1.0000000 0.6819780 0.5924644 0.3844298
: B1_week   0.6819780 1.0000000 0.7996891 0.2103374
: A1_week   0.5924644 0.7996891 1.0000000 0.2533221
: A3_months 0.3844298 0.2103374 0.2533221 1.0000000

The long format:
#+begin_src R :exports both :results output :session *R* :cache no
gastricbypassL$residualsN_CS <- residuals(eCS.lmm, type.residual = "normalized",
                                          format = "long")
#+end_src

#+RESULTS:

 can be useful to investigate trends relative to a covariate:
#+begin_src R :exports code :results output :session *R* :cache no
library(ggplot2)
ggplot(gastricbypassL, aes(x=glucagon,y=residualsN_CS)) + geom_point() + geom_smooth()
#+end_src

#+RESULTS:
: `geom_smooth()` using method = 'loess' and formula 'y ~ x'
: Warning messages:
: 1: Removed 2 rows containing non-finite values (stat_smooth). 
: 2: Removed 2 rows containing missing values (geom_point).

#+ATTR_LaTeX: :width 0.5\textwidth :placement [!h]
[[./figures/diag-cov.pdf]]

# ## ggsave(ggplot(gastricbypassL, aes(x=glucagon,y=residualsN_CS)) + geom_point() + geom_smooth() + theme(text = element_text(size=20)), filename = "figures/diag-cov.pdf")

\clearpage

or to look at the distribution of the residuals via a qq-plot:
#+begin_src R :exports both :results output :session *R* :cache no
library(qqtest)
qqtest(na.omit(gastricbypassL$residualsN_CS))
#+end_src
#+RESULTS:

#+ATTR_LaTeX: :width 0.5\textwidth :placement [!h]
[[./figures/diag-qqplot.pdf]]

# ## pdf("figures/diag-qqplot.pdf"); qqtest(na.omit(gastricbypassL$residualsN_CS)) ; dev.off()

** Model fit

The fitted values can be displayed via the =emmeans= package or using the =autoplot= method:
#+begin_src R :exports both :results output :session *R* :cache no
library(emmeans) ## left panel
emmip(eCS.lmm, ~time)
library(ggplot2) ## right panel
autoplot(eCS.lmm)
#+end_src

#+RESULTS:

#+latex: \begin{minipage}{0.45\linewidth}
#+ATTR_LaTeX: :width \textwidth :placement [!h]
[[./figures/fit-emmip.pdf]]
#+latex: \end{minipage}
#+latex: \begin{minipage}{0.45\linewidth}
#+ATTR_LaTeX: :width \textwidth :placement [!h]
[[./figures/fit-autoplot.pdf]]
#+latex: \end{minipage}

# ## ggsave(emmip(eCS.lmm, ~time) + theme(text = element_text(size=20)), filename = "figures/fit-emmip.pdf")
# ## ggsave(autoplot(eCS.lmm, plot = FALSE)$plot + theme(text = element_text(size=20)), filename = "figures/fit-autoplot.pdf")

In the first case the average curve (over glucago values) is displayed
while in the latter each possible curve is displayed. With the
=autoplot= method, it is possible to display a curve specific to a
glucagon value via the argument =at=:
#+begin_src R :exports both :results output :session *R* :cache no
autoplot(eCS.lmm, at = data.frame(glucagon = 10), color = "glucagon")
#+end_src

#+RESULTS:

** Statistical inference

*** Model coefficients

The estimated coefficients with their confidence intervals can be accessed via the =confint= method:
#+begin_src R :exports both :results output :session *R* :cache no
confint(eCS.lmm)
#+end_src

#+RESULTS:
:                  estimate        se  statistic        df       lower      upper null      p.value
: (Intercept)   129.3690995 4.2256315  30.615329 20.223686 120.5608325 138.177367    0 0.000000e+00
: timeB1_week    -7.6194918 1.0538287  -7.230294 54.431370  -9.7319078  -5.507076    0 1.670235e-09
: timeA1_week   -14.4951323 1.4279420 -10.151066 53.729569 -17.3583136 -11.631951    0 4.263256e-14
: timeA3_months -27.0514694 1.0870635 -24.884902 54.286480 -29.2306372 -24.872302    0 0.000000e+00
: glucagon        0.8217879 0.6199594   1.325551 53.053075  -0.4216641   2.065240    0 1.906683e-01
: log(sigma)      2.9364900 0.1580448         NA  5.518946   2.5414485   3.331532   NA           NA
: atanh(Rho)      2.0911816 0.1866252  11.205249  3.251184   1.5223905   2.659973    0 1.044455e-03

The variance and correlation parameters being constrained parameters
(e.g. strictly positive), they uncertainty is by default computed
after transformation (e.g. =log=):
#+begin_src R :exports both :results output :session *R* :cache no
confint(eCS.lmm, effects = "variance")
#+end_src

#+RESULTS:
:            estimate        se statistic       df    lower    upper null p.value
: log(sigma)  2.93649 0.1580448        NA 5.518946 2.541448 3.331532   NA      NA

They can be backtransformed to the original scale using =backtransform=:

#+begin_src R :exports both :results output :session *R* :cache no
backtransform(confint(eCS.lmm, effects = "variance"))
#+end_src

#+RESULTS:
:       estimate        se statistic       df    lower    upper null p.value
: sigma 18.84957 0.1580448        NA 5.518946 12.69805 27.98116   NA      NA
: Note: estimates and confidence intervals for sigma, k, rho have been back-transformed. 
:       standard errors are not back-transformed.

While not recommanded, it is also possible to not use any transformation:
#+begin_src R :exports both :results output :session *R* :cache no
table <- confint(eCS.lmm, effects = "variance", transform.sigma = "none")
table
#+end_src

#+RESULTS:
:       estimate       se statistic       df    lower    upper null p.value
: sigma 18.84957 2.979077        NA 1.626596 2.754492 34.94464   NA      NA

*** Linear combination of the model coefficients

The =anova= method can be use to test one or several linear
combinations of the model coefficients using Wald tests. For instance
whether there is a change in average weight just after taking the
treatment:
#+begin_src R :exports both :results output :session *R* :cache no
anova(eUN.lmm, effects = c("timeA1_week-timeB1_week=0"), ci = TRUE)
#+end_src

#+RESULTS:
#+begin_example

                     ,** User-specified hypotheses ** 
 - F-test
 statistic df.num df.denom      p.value
  43.15392      1 17.78688 3.808793e-06

 - P-values and confidence interval (adjusted for multiplicity within each global test) 
                           estimate        se       df statistic     lower     upper null
timeA1_week - timeB1_week -3.905721 0.5945537 17.78688 -6.569165 -5.155906 -2.655536    0
                               p.value
timeA1_week - timeB1_week 3.808793e-06
#+end_example

When testing transformed variance or correlation parameters,
parentheses (as in =log(k).B1_week=) cause problem for recognizing
parameters:
#+begin_src R :exports both :results output :session *R* :cache no
try(
  anova(eUN.lmm,
        effects = c("log(k).B1_week=0","log(k).A1_week=0","log(k).A3_months=0"))
)
#+end_src

#+RESULTS:
: Error in .anova_Wald(object, effects = effects, rhs = rhs, df = df, ci = ci,  : 
:   Possible mispecification of the argument 'effects' as running mulcomp::glht lead to the following error: 
: Error in parse(text = ex[i]) : <text>:1:7: unexpected symbol
: 1: log(k).B1_week
:           ^

It is then advised to specify the null hypothesis via a contrast matrix, e.g.:
#+begin_src R :exports both :results output :session *R* :cache no
name.coef <- names(coef(eUN.lmm))
name.varcoef <- grep("log(k)",name.coef, value = TRUE, fixed = TRUE)
C <- matrix(0, nrow = 3, ncol = length(name.coef), dimnames = list(name.varcoef, name.coef))
diag(C[name.varcoef,name.varcoef]) <- 1

anova(eUN.lmm, effects = C)
#+end_src

#+RESULTS:
: 
:                      ** User-specified hypotheses ** 
:  - F-test
:  statistic df.num df.denom     p.value
:   6.234317      3 18.02975 0.004307772


\clearpage

** Baseline adjustment

The =lmm= contains an "experimental" feature to drop non-identifiable
effects from the model. For instance, let us define two (artifical) groups of
patients:
#+begin_src R :exports both :results output :session *R* :cache no
gastricbypassL$group <- c("1","2")[as.numeric(gastricbypassL$id) %in% 15:20 + 1]
#+end_src
#+RESULTS:
We would like to model group differences only after baseline
(i.e. only at 1 week and 3 months after). For this we will define a
treatment variable being the group variable except before baseline where
it is ="none"=:
#+begin_src R :exports both :results output :session *R* :cache no
gastricbypassL$treatment <- factor(gastricbypassL$group, c("none","1","2"))
gastricbypassL$treatment[gastricbypassL$time %in% c("B3_months","B1_week")] <- "none"
table(gastricbypassL$treatment, gastricbypassL$time)
#+end_src

#+RESULTS:
:       
:        B3_months B1_week A1_week A3_months
:   none        20      20       0         0
:   1            0       0      14        14
:   2            0       0       6         6

Here we will be able to estimate a total of 6 means and therefore can
at most identify 6 effects. However the design matrix for the
interaction model:
#+begin_src R :exports both :results output :session *R* :cache no
colnames(model.matrix(weight ~ treatment*time, data = gastricbypassL))
#+end_src

#+RESULTS:
:  [1] "(Intercept)"              "treatment1"               "treatment2"              
:  [4] "timeB1_week"              "timeA1_week"              "timeA3_months"           
:  [7] "treatment1:timeB1_week"   "treatment2:timeB1_week"   "treatment1:timeA1_week"  
: [10] "treatment2:timeA1_week"   "treatment1:timeA3_months" "treatment2:timeA3_months"

contains 12 parameters (i.e. 6 too many). The =lmm= function will
internally remove the one that cannot be identified and fit a
simplified model:
#+begin_src R :exports both :results output :session *R* :cache no
eC.lmm <- lmm(weight ~ treatment*time, data = gastricbypassL, structure = UN(~time|id))
#+end_src

#+RESULTS:
: Warning message:
: In model.matrix_regularize(formula.mean, data) :
:   Constant values in the design matrix in interactions "treatment:time"
:  Coefficients "treatment1" "treatment2" "timeA1_week" "timeA3_months" "treatment1:timeB1_week" "treatment2:timeB1_week" will be removed from the design matrix. 
: Consider defining manually the interaction, e.g. via droplevels(interaction(.,.)) to avoid this warning.

with the following coefficients:
#+begin_src R :exports both :results output :session *R* :cache no
coef(eC.lmm, effects = "mean")
#+end_src

#+RESULTS:
:              (Intercept)              timeB1_week   treatment1:timeA1_week   treatment2:timeA1_week 
:                128.97000                 -7.73000                -12.83949                -14.27452 
: treatment1:timeA3_months treatment2:timeA3_months 
:                -27.07620                -25.50553

One can vizualize the baseline adjustment via the =autoplot= function:
#+begin_src R :exports both :results output :session *R* :cache no
autoplot(eC.lmm, color = "group", ci = FALSE)
#+end_src

#+RESULTS:

#+ATTR_LaTeX: :width 0.5\textwidth :placement [!h]
[[./figures/gg-baseAdj.pdf]]

# ## ggsave(autoplot(eC.lmm, color = "group", ci = FALSE, plot = FALSE)$plot + theme(text = element_text(size=20)), filename = "figures/gg-baseAdj.pdf")

\clearpage
* Data generation
Simulate some data in the wide format:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
set.seed(10) ## ensure reproductibility
n.obs <- 100
n.times <- 4
mu <- rep(0,4)
gamma <- matrix(0, nrow = n.times, ncol = 10) ## add interaction
gamma[,6] <- c(0,1,1.5,1.5)
dW <- sampleRem(n.obs, n.times = n.times, mu = mu, gamma = gamma, format = "wide")
head(round(dW,3))
#+END_SRC

#+RESULTS:
:   id X1 X2 X3 X4 X5     X6     X7     X8    X9    X10     Y1     Y2     Y3     Y4
: 1  1  1  0  1  1  0 -0.367  1.534 -1.894 1.729  0.959  1.791  2.429  3.958  2.991
: 2  2  1  0  1  2  0 -0.410  2.065  1.766 0.761 -0.563  2.500  4.272  3.002  2.019
: 3  3  0  0  2  1  0 -1.720 -0.178  2.357 1.966  1.215 -3.208 -5.908 -4.277 -5.154
: 4  4  0  0  0  1  0  0.923 -2.089  0.233 1.307 -0.906 -2.062  0.397  1.757 -1.380
: 5  5  0  0  2  1  0  0.987  5.880  0.385 0.028  0.820  7.963  7.870  7.388  8.609
: 6  6  0  0  1  1  2 -1.075  0.479  2.202 0.900 -0.739  0.109 -1.602 -1.496 -1.841

Simulate some data in the long format:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
set.seed(10) ## ensure reproductibility
dL <- sampleRem(n.obs, n.times = n.times, mu = mu, gamma = gamma, format = "long")
head(dL)
#+END_SRC

#+RESULTS:
:   id visit        Y X1 X2 X3 X4 X5         X6       X7        X8        X9        X10
: 1  1     1 1.791444  1  0  1  1  0 -0.3665251 1.533815 -1.894425 1.7288665  0.9592499
: 2  1     2 2.428570  1  0  1  1  0 -0.3665251 1.533815 -1.894425 1.7288665  0.9592499
: 3  1     3 3.958350  1  0  1  1  0 -0.3665251 1.533815 -1.894425 1.7288665  0.9592499
: 4  1     4 2.991198  1  0  1  1  0 -0.3665251 1.533815 -1.894425 1.7288665  0.9592499
: 5  2     1 2.500179  1  0  1  2  0 -0.4097541 2.065413  1.765841 0.7613348 -0.5630173
: 6  2     2 4.272357  1  0  1  2  0 -0.4097541 2.065413  1.765841 0.7613348 -0.5630173

\clearpage

* Modifying default options
The =LMMstar.options= method enable to get and set the default options
used by the package. For instance, the default option for the information matrix is:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
LMMstar.options("type.information")
#+END_SRC

#+RESULTS:
: $type.information
: [1] "observed"

To change the default option to "expected" (faster to compute but less accurate p-values and confidence intervals in small samples) use:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
LMMstar.options(type.information = "expected")
#+END_SRC

To restore the original default options do:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
LMMstar.options(reinitialise = TRUE)
#+END_SRC

#+RESULTS:

\clearpage

* R session
Details of the R session used to generate this document:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
sessionInfo()
#+END_SRC

#+RESULTS:
#+begin_example
R version 4.1.0 (2021-05-18)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Ubuntu 20.04.2 LTS

Matrix products: default
BLAS:   /usr/lib/x86_64-linux-gnu/blas/libblas.so.3.9.0
LAPACK: /usr/lib/x86_64-linux-gnu/lapack/liblapack.so.3.9.0

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C               LC_TIME=en_US.UTF-8       
 [4] LC_COLLATE=en_US.UTF-8     LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8   
 [7] LC_PAPER=en_US.UTF-8       LC_NAME=C                  LC_ADDRESS=C              
[10] LC_TELEPHONE=C             LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
[1] LMMstar_0.2

loaded via a namespace (and not attached):
 [1] Rcpp_1.0.6          plyr_1.8.6          pillar_1.6.1        compiler_4.1.0     
 [5] tools_4.1.0         lifecycle_1.0.0     tibble_3.1.2        gtable_0.3.0       
 [9] nlme_3.1-152        lattice_0.20-44     pkgconfig_2.0.3     rlang_0.4.11       
[13] Matrix_1.3-3        mvtnorm_1.1-1       coda_0.19-4         stringr_1.4.0      
[17] dplyr_1.0.6         generics_0.1.0      vctrs_0.3.8         grid_4.1.0         
[21] tidyselect_1.1.1    glue_1.4.2          R6_2.5.0            fansi_0.4.2        
[25] survival_3.2-11     multcomp_1.4-17     lava_1.6.9          TH.data_1.0-10     
[29] reshape2_1.4.4      ggplot2_3.3.3       purrr_0.3.4         magrittr_2.0.1     
[33] scales_1.1.1        codetools_0.2-18    ellipsis_0.3.2      emmeans_1.6.0      
[37] MASS_7.3-54         splines_4.1.0       xtable_1.8-4        colorspace_2.0-1   
[41] numDeriv_2016.8-1.1 sandwich_3.0-1      utf8_1.2.1          stringi_1.6.2      
[45] estimability_1.3    munsell_0.5.0       crayon_1.4.1        zoo_1.8-9
#+end_example

\clearpage

* References
:PROPERTIES:
:UNNUMBERED: t
:END:

#+BEGIN_EXPORT latex
\begingroup
\renewcommand{\section}[2]{}
#+END_EXPORT

bibliographystyle:apalike
[[bibliography:bibliography.bib]]

#+BEGIN_EXPORT latex
\endgroup
#+END_EXPORT

\clearpage

#+BEGIN_EXPORT LaTeX
\appendix
\titleformat{\section}
{\normalfont\Large\bfseries}{Appendix~\thesection}{1em}{}

\renewcommand{\thefigure}{\Alph{figure}}
\renewcommand{\thetable}{\Alph{table}}
\renewcommand{\theequation}{\Alph{equation}}

\setcounter{figure}{0}    
\setcounter{table}{0}    
\setcounter{equation}{0}    
#+END_EXPORT

* Likelihood in a multivariate Gaussian models
:PROPERTIES:
:CUSTOM_ID: SM:likelihood
:END:

** Log-likelihood

Denote by \(\VY\) a vector of \(m\) outcomes, \(\VX\) a vector of
\(p\) covariates, \(\mu(\Vparam,\VX)\) the modeled mean, and
\(\Omega(\Vparam,\VX)\) the modeled residual variance-covariance. The
restricted log-likelihood in a linear Gaussian model can then be
written:
 #+BEGIN_EXPORT LaTeX
\begin{align*}
\Likelihood(\Vparam|\VY,\VX) =& \textcolor{\darkred}{ \frac{p}{2} \log(2\pi)-\frac{1}{2} \log\left(\left|\sum_{i=1}^n \VX_i \Omega_i^{-1}(\Vparam) \trans{\VX}_i\right|\right)} \\
& + \sum_{i=1}^{n} \left(\textcolor{\darkblue}{-\frac{m}{2} \log(2\pi) - \frac{1}{2} \log\left|\Omega_i(\Vparam)\right| - \frac{1}{2} (\VY_i-\mu(\Vparam,\VX_i)) \Omega_i(\Vparam)^{-1} \trans{(\VY_i-\mu(\Vparam,\VX_i))}} \right) 
\end{align*}
 #+END_EXPORT
 
 This is what the =logLik= method is computing for the REML
 criteria. The red term is specific to the REML criteria and prevents
 from computing individual contributions to the likelihood[fn::The REML is the
 likelihood of the observations divided by the prior on the estimated
 mean parameters \(\VparamHat_{\mu} \sim \Gaus(\mu,\left(\VX
 \Omega^{-1}(\Vparam) \trans{\VX}\right)^{-1})\). This corresponds to
 \(\frac{1}{\sqrt{2\pi}^p \left|\left(\sum_{i=1}^n \VX_i
 \Omega_i^{-1}(\Vparam) \trans{\VX}_i\right)^{-1}\right|}
 \exp\left(-(\VparamHat_{\mu}-\mu)\left(2\sum_{i=1}^n \VX_i
 \Omega_i^{-1}(\Vparam)
 \trans{\VX}_i\right)^{-1})\trans{(\VparamHat_{\mu}-\mu)}\right)\)
 Since \(\mu\) will be estimated to be \(\Vparam_{\mu}\), the
 exponential term equals 1 and thus does not contribute to the
 log-likelihood. One divided by the other term gives \(\sqrt{2\pi}^p
 \left(\left|\sum_{i=1}^n \VX_i \Omega_i^{-1}(\Vparam)
 \trans{\VX}_i\right|\right)^{-1}\). The log of this term equals the red
 term]. The blue term is what =logLik= outputs for the ML criteria
 when setting the argument =indiv= to =TRUE=.

\bigskip
 
** Score

 Using that \(\partial \log(\det(X))=tr(X^{-1}\partial(X))\), the
score is obtained by derivating once the log-likelihood, i.e., for
\(\theta \in \Vparam\):
#+BEGIN_EXPORT LaTeX
\begin{align*}
   \Score(\theta) =& \dpartial[\Likelihood(\Vparam|\VY,\VX)][\theta]
= \textcolor{\darkred}{ \frac{1}{2} tr \left( \left(\sum_{i=1}^n \VX_i \Omega_i^{-1}(\Vparam) \trans{\VX}_i\right)^{-1} \left(\sum_{i=1}^n \VX_i \Omega_i^{-1}(\Vparam) \dpartial[\Omega_i(\Vparam)][\theta] \Omega_i(\Vparam)^{-1} \trans{\VX}_i\right)  \right) } \\
&+ \sum_{i=1}^n \left( \textcolor{\darkblue}{ -\frac{1}{2} tr\left(\Omega_i(\Vparam)^{-1} \dpartial[\Omega_i(\Vparam)][\theta]\right) + \dpartial[\mu(\Vparam,\VX_i)][\theta] \Omega_i(\Vparam)^{-1} \trans{(\VY_i-\mu(\Vparam,\VX_i))} } \right. \\
 & \qquad \qquad \left. \textcolor{\darkblue}{ + \frac{1}{2} (\VY_i-\mu(\Vparam,\VX_i)) \Omega_i(\Vparam)^{-1} \dpartial[\Omega_i(\Vparam)][\theta] \Omega_i(\Vparam)^{-1} \trans{(\VY_i-\mu(\Vparam,\VX_i))} } \right).
\end{align*}
#+END_EXPORT

 This is what the =score= method is computing for the REML
 criteria. The red term is specific to the REML criteria and prevents
 from computing the score relative to each cluster. The blue term is
 what =score= outputs for the ML criteria when setting the argument
 =indiv= to =TRUE=.

\bigskip

\clearpage

** Hessian

Derivating a second time the log-likelihood gives the hessian, \(\Hessian(\Vparam)\), with element[fn::if one is relative to the mean and the other to the variance then they are respectively \(\theta\) and \(\theta'\)]:
#+BEGIN_EXPORT LaTeX
\begin{align*}
& \Hessian(\theta,\theta^{\prime}) = \ddpartial[\Likelihood(\Vparam|\VY,\VX)][\theta][\theta^{\prime}] = \dpartial[\Score(\theta)][\theta^{\prime}] \\
=& \textcolor{\darkred}{\frac{1}{2} tr \left( \left(\sum_{i=1}^n \VX_i \Omega_i^{-1}(\Vparam) \trans{\VX}_i\right)^{-1} \left\{ \sum_{i=1}^n \VX_i \Omega_i^{-1}(\Vparam) \left(\ddpartial[\Omega_i(\Vparam)][\theta][\theta^{\prime}] - 2 \dpartial[\Omega_i(\Vparam)][\theta] \Omega_i^{-1}(\Vparam) \dpartial[\Omega_i(\Vparam)][\theta^{\prime}]\right)\Omega_i(\Vparam)^{-1} \trans{\VX}_i \right.  \right.}  \\
& \textcolor{\darkred}{ \left. \left. \qquad + \left(\sum_{i=1}^n \VX_i \Omega_i^{-1}(\Vparam) \dpartial[\Omega_i(\Vparam)][\theta] \Omega_i(\Vparam)^{-1} \trans{\VX}_i\right) \left(\sum_{i=1}^n \VX_i\Omega_i^{-1}(\Vparam) \trans{\VX}_i \right) \left(\sum_{i=1}^n \VX_i \Omega_i^{-1}(\Vparam) \dpartial[\Omega_i(\Vparam)][\theta^{\prime}] \Omega_i(\Vparam)^{-1} \trans{\VX}_i\right) \right\} \right) } \\
& +\sum_{i=1}^n \left( \textcolor{\darkblue}{ \frac{1}{2} tr\left(\Omega_i(\Vparam)^{-1} \dpartial[\Omega_i(\Vparam)][\theta^{\prime}] \Omega_i(\Vparam)^{-1} \dpartial[\Omega_i(\Vparam)][\theta] - \Omega_i(\Vparam)^{-1} \ddpartial[\Omega_i(\Vparam)][\theta][\theta^{\prime}] \right) } \right.\\
& \qquad \qquad \textcolor{\darkblue}{ -  \dpartial[\mu(\Vparam,\VX_i)][\theta] \Omega_i(\Vparam)^{-1} \dpartial[\Omega_i(\Vparam)^{-1}][\theta^{\prime}] \Omega_i(\Vparam)^{-1} \trans{(\VY_i-\mu(\Vparam,\VX_i))} - \dpartial[\mu(\Vparam,\VX_i)][\theta] \Omega_i(\Vparam)^{-1} \trans{\dpartial[\mu(\Vparam,\VX_i)][\theta^{\prime}]} } \\
& \qquad \qquad \left. \textcolor{\darkblue}{ + \frac{1}{2} (\VY_i-\mu(\Vparam,\VX_i)) \Omega_i(\Vparam)^{-1} \left(\ddpartial[\Omega_i(\Vparam)][\theta][\theta^{\prime}] - 2\dpartial[\Omega_i(\Vparam)][\theta^{\prime}] \Omega_i(\Vparam)^{-1} \dpartial[\Omega_i(\Vparam)][\theta] \right) \Omega_i(\Vparam)^{-1} \trans{(\VY_i-\mu(\Vparam,\VX_i))} } \right).
\end{align*}
#+END_EXPORT

The =information= method will (by default) return the (observed)
information which is the opposite of the hessian. So multiplying the
previous formula by -1 gives what =inforamtion= output for the REML
criteria. The red term is specific to the REML criteria and prevents
from computing the information relative to each cluster. The blue term
is what =information= outputs for the ML criteria (up to a factor -1)
when setting the argument =indiv= to =TRUE=.

\bigskip

A possible simplification is to use the expected hessian. Indeed for
any deterministic matrix \(A\):
- \(\Esp[A \trans{(\VY_i-\mu(\Vparam,\VX_i))}|\VX_i] = 0\)
- \(\Esp[(\VY_i-\mu(\Vparam,\VX_i)) A \trans{(\VY_i-\mu(\Vparam,\VX_i))}||\VX_i] = tr(A \Var(\VY_i-\mu(\Vparam,\VX_i)))\)
Leading to:
#+BEGIN_EXPORT LaTeX
\begin{align*}
 & \Esp[\Hessian(\theta,\theta^{\prime})|\VX] \\
 &= \textcolor{\darkred}{ \frac{1}{2} tr \left( \left(\sum_{i=1}^n \VX_i \Omega_i^{-1}(\Vparam) \trans{\VX}_i\right)^{-1}  \left\{ \sum_{i=1}^n \VX_i \Omega_i^{-1}(\Vparam) \left( \ddpartial[\Omega_i(\Vparam)][\theta][\theta^{\prime}] - 2 \dpartial[\Omega_i(\Vparam)][\theta]  \Omega_i^{-1}(\Vparam) \dpartial[\Omega_i(\Vparam)][\theta^{\prime}]\right) \Omega_i(\Vparam)^{-1} \trans{\VX}_i \right.  \right.}  \\
 & \textcolor{\darkred}{ \left. \left. \qquad +  \left(\sum_{i=1}^n \VX_i \Omega_i^{-1}(\Vparam) \dpartial[\Omega_i(\Vparam)][\theta] \Omega_i(\Vparam)^{-1} \trans{\VX}_i\right) \left(\sum_{i=1}^n \VX_i \Omega_i^{-1}(\Vparam) \trans{\VX}_i \right) \left(\sum_{i=1}^n \VX_i \Omega_i^{-1}(\Vparam) \dpartial[\Omega_i(\Vparam)][\theta^{\prime}] \Omega_i(\Vparam)^{-1} \trans{\VX}_i\right) \right\} \right) } \\
 & + \sum_{i=1}^n \left( \textcolor{\darkblue}{
- \frac{1}{2} tr\left(\Omega_i(\Vparam)^{-1} \dpartial[\Omega_i(\Vparam)][\theta^{\prime}] \Omega_i(\Vparam)^{-1} \dpartial[\Omega_i(\Vparam)][\theta]\right)
 - \dpartial[\mu(\Vparam,\VX_i)][\theta] \Omega_i(\Vparam)^{-1} \trans{\dpartial[\mu(\Vparam,\VX_i)][\theta^{\prime}]}
 } \right) \\
\end{align*}
#+END_EXPORT

This is what =information= output when the argument =type.information=
is set to ="expected"= (up to a factor -1).

  
* CONFIG                                                           :noexport:
#+LANGUAGE:  en
#+LaTeX_CLASS: org-article
#+LaTeX_CLASS_OPTIONS: [12pt]
#+OPTIONS:   title:t author:t toc:nil todo:nil
#+OPTIONS:   H:3 num:t 
#+OPTIONS:   TeX:t LaTeX:t
** Display of the document
# ## space between lines
#+LATEX_HEADER: \RequirePackage{setspace} % to modify the space between lines - incompatible with footnote in beamer
#+LaTeX_HEADER:\renewcommand{\baselinestretch}{1.1}
# ## margins
#+LaTeX_HEADER: \geometry{a4paper, left=10mm, right=10mm, top=10mm}
# ## personalize the prefix in the name of the sections
#+LaTeX_HEADER: \usepackage{titlesec}
# ## fix bug in titlesec version
# ##  https://tex.stackexchange.com/questions/299969/titlesec-loss-of-section-numbering-with-the-new-update-2016-03-15
#+LaTeX_HEADER: \usepackage{etoolbox}
#+LaTeX_HEADER: 
#+LaTeX_HEADER: \makeatletter
#+LaTeX_HEADER: \patchcmd{\ttlh@hang}{\parindent\z@}{\parindent\z@\leavevmode}{}{}
#+LaTeX_HEADER: \patchcmd{\ttlh@hang}{\noindent}{}{}{}
#+LaTeX_HEADER: \makeatother
** Color
# ## define new colors
#+LATEX_HEADER: \RequirePackage{colortbl} % arrayrulecolor to mix colors
#+LaTeX_HEADER: \definecolor{myorange}{rgb}{1,0.2,0}
#+LaTeX_HEADER: \definecolor{mypurple}{rgb}{0.7,0,8}
#+LaTeX_HEADER: \definecolor{mycyan}{rgb}{0,0.6,0.6}
#+LaTeX_HEADER: \newcommand{\lightblue}{blue!50!white}
#+LaTeX_HEADER: \newcommand{\darkblue}{blue!80!black}
#+LaTeX_HEADER: \newcommand{\darkgreen}{green!50!black}
#+LaTeX_HEADER: \newcommand{\darkred}{red!50!black}
#+LaTeX_HEADER: \definecolor{gray}{gray}{0.5}
# ## change the color of the links
#+LaTeX_HEADER: \hypersetup{
#+LaTeX_HEADER:  citecolor=[rgb]{0,0.5,0},
#+LaTeX_HEADER:  urlcolor=[rgb]{0,0,0.5},
#+LaTeX_HEADER:  linkcolor=[rgb]{0,0,0.5},
#+LaTeX_HEADER: }
** Font
# https://tex.stackexchange.com/questions/25249/how-do-i-use-a-particular-font-for-a-small-section-of-text-in-my-document
#+LaTeX_HEADER: \newenvironment{note}{\small \color{gray}\fontfamily{lmtt}\selectfont}{\par}
#+LaTeX_HEADER: \newenvironment{activity}{\color{orange}\fontfamily{qzc}\selectfont}{\par}
** Symbols
# ## valid and cross symbols
#+LaTeX_HEADER: \RequirePackage{pifont}
#+LaTeX_HEADER: \RequirePackage{relsize}
#+LaTeX_HEADER: \newcommand{\Cross}{{\raisebox{-0.5ex}%
#+LaTeX_HEADER:		{\relsize{1.5}\ding{56}}}\hspace{1pt} }
#+LaTeX_HEADER: \newcommand{\Valid}{{\raisebox{-0.5ex}%
#+LaTeX_HEADER:		{\relsize{1.5}\ding{52}}}\hspace{1pt} }
#+LaTeX_HEADER: \newcommand{\CrossR}{ \textcolor{red}{\Cross} }
#+LaTeX_HEADER: \newcommand{\ValidV}{ \textcolor{green}{\Valid} }
# ## warning symbol
#+LaTeX_HEADER: \usepackage{stackengine}
#+LaTeX_HEADER: \usepackage{scalerel}
#+LaTeX_HEADER: \newcommand\Warning[1][3ex]{%
#+LaTeX_HEADER:   \renewcommand\stacktype{L}%
#+LaTeX_HEADER:   \scaleto{\stackon[1.3pt]{\color{red}$\triangle$}{\tiny\bfseries !}}{#1}%
#+LaTeX_HEADER:   \xspace
#+LaTeX_HEADER: }
# # R Software
#+LATEX_HEADER: \newcommand\Rlogo{\textbf{\textsf{R}}\xspace} % 
** Code
:PROPERTIES:
:ID: 2ec77c4b-f83d-4612-9a89-a96ba1b7bf70
:END:
# Documentation at https://org-babel.readthedocs.io/en/latest/header-args/#results
# :tangle (yes/no/filename) extract source code with org-babel-tangle-file, see http://orgmode.org/manual/Extracting-source-code.html 
# :cache (yes/no)
# :eval (yes/no/never)
# :results (value/output/silent/graphics/raw/latex)
# :export (code/results/none/both)
#+PROPERTY: header-args :session *R* :tangle yes :cache no ## extra argument need to be on the same line as :session *R*
# Code display:
#+LATEX_HEADER: \RequirePackage{fancyvrb}
#+LATEX_HEADER: \DefineVerbatimEnvironment{verbatim}{Verbatim}{fontsize=\small,formatcom = {\color[rgb]{0.5,0,0}}}
# ## change font size input (global change)
# ## doc: https://ctan.math.illinois.edu/macros/latex/contrib/listings/listings.pdf
# #+LATEX_HEADER: \newskip kipamount    kipamount =6pt plus 0pt minus 6pt
# #+LATEX_HEADER: \lstdefinestyle{code-tiny}{basicstyle=\ttfamily\tiny, aboveskip =  kipamount, belowskip =  kipamount}
# #+LATEX_HEADER: \lstset{style=code-tiny}
# ## change font size input (local change, put just before BEGIN_SRC)
# ## #+ATTR_LATEX: :options basicstyle=\ttfamily\scriptsize
# ## change font size output (global change)
# ## \RecustomVerbatimEnvironment{verbatim}{Verbatim}{fontsize=\tiny,formatcom = {\color[rgb]{0.5,0,0}}}
** Lists
#+LATEX_HEADER: \RequirePackage{enumitem} % better than enumerate
** Image and graphs
#+LATEX_HEADER: \RequirePackage{epstopdf} % to be able to convert .eps to .pdf image files
#+LATEX_HEADER: \RequirePackage{capt-of} % 
#+LATEX_HEADER: \RequirePackage{caption} % newlines in graphics
#+LaTeX_HEADER: \RequirePackage{tikz-cd} % graph
# ## https://tools.ietf.org/doc/texlive-doc/latex/tikz-cd/tikz-cd-doc.pdf
** Table
#+LATEX_HEADER: \RequirePackage{booktabs} % for nice lines in table (e.g. toprule, bottomrule, midrule, cmidrule)
** Inline latex
# @@latex:any arbitrary LaTeX code@@
** Algorithm
#+LATEX_HEADER: \RequirePackage{amsmath}
#+LATEX_HEADER: \RequirePackage{algorithm}
#+LATEX_HEADER: \RequirePackage[noend]{algpseudocode}
** Math
#+LATEX_HEADER: \RequirePackage{dsfont}
#+LATEX_HEADER: \RequirePackage{amsmath,stmaryrd,graphicx}
#+LATEX_HEADER: \RequirePackage{prodint} % product integral symbol (\PRODI)
# ## lemma
# #+LaTeX_HEADER: \RequirePackage{amsthm}
# #+LaTeX_HEADER: \newtheorem{theorem}{Theorem}
# #+LaTeX_HEADER: \newtheorem{lemma}[theorem]{Lemma}
*** Template for shortcut
#+LATEX_HEADER: \usepackage{ifthen}
#+LATEX_HEADER: \usepackage{xifthen}
#+LATEX_HEADER: \usepackage{xargs}
#+LATEX_HEADER: \usepackage{xspace}
#+LATEX_HEADER: \newcommand\defOperator[7]{%
#+LATEX_HEADER:	\ifthenelse{\isempty{#2}}{
#+LATEX_HEADER:		\ifthenelse{\isempty{#1}}{#7{#3}#4}{#7{#3}#4 \left#5 #1 \right#6}
#+LATEX_HEADER:	}{
#+LATEX_HEADER:	\ifthenelse{\isempty{#1}}{#7{#3}#4_{#2}}{#7{#3}#4_{#1}\left#5 #2 \right#6}
#+LATEX_HEADER: }
#+LATEX_HEADER: }
#+LATEX_HEADER: \newcommand\defUOperator[5]{%
#+LATEX_HEADER: \ifthenelse{\isempty{#1}}{
#+LATEX_HEADER:		#5\left#3 #2 \right#4
#+LATEX_HEADER: }{
#+LATEX_HEADER:	\ifthenelse{\isempty{#2}}{\underset{#1}{\operatornamewithlimits{#5}}}{
#+LATEX_HEADER:		\underset{#1}{\operatornamewithlimits{#5}}\left#3 #2 \right#4}
#+LATEX_HEADER: }
#+LATEX_HEADER: }
#+LATEX_HEADER: \newcommand{\defBoldVar}[2]{	
#+LATEX_HEADER:	\ifthenelse{\equal{#2}{T}}{\boldsymbol{#1}}{\mathbf{#1}}
#+LATEX_HEADER: }
**** Probability
#+LATEX_HEADER: \newcommandx\Esp[2][1=,2=]{\defOperator{#1}{#2}{E}{}{\lbrack}{\rbrack}{\mathbb}}
#+LATEX_HEADER: \newcommandx\Prob[2][1=,2=]{\defOperator{#1}{#2}{P}{}{\lbrack}{\rbrack}{\mathbb}}
#+LATEX_HEADER: \newcommandx\Qrob[2][1=,2=]{\defOperator{#1}{#2}{Q}{}{\lbrack}{\rbrack}{\mathbb}}
#+LATEX_HEADER: \newcommandx\Var[2][1=,2=]{\defOperator{#1}{#2}{V}{ar}{\lbrack}{\rbrack}{\mathbb}}
#+LATEX_HEADER: \newcommandx\Cov[2][1=,2=]{\defOperator{#1}{#2}{C}{ov}{\lbrack}{\rbrack}{\mathbb}}
#+LATEX_HEADER: \newcommandx\Binom[2][1=,2=]{\defOperator{#1}{#2}{B}{}{(}{)}{\mathcal}}
#+LATEX_HEADER: \newcommandx\Gaus[2][1=,2=]{\defOperator{#1}{#2}{N}{}{(}{)}{\mathcal}}
#+LATEX_HEADER: \newcommandx\Wishart[2][1=,2=]{\defOperator{#1}{#2}{W}{ishart}{(}{)}{\mathcal}}
#+LATEX_HEADER: \newcommandx\Likelihood[2][1=,2=]{\defOperator{#1}{#2}{L}{}{(}{)}{\mathcal}}
#+LATEX_HEADER: \newcommandx\logLikelihood[2][1=,2=]{\defOperator{#1}{#2}{\ell}{}{(}{)}{}}
#+LATEX_HEADER: \newcommandx\Information[2][1=,2=]{\defOperator{#1}{#2}{I}{}{(}{)}{\mathcal}}
#+LATEX_HEADER: \newcommandx\Hessian[2][1=,2=]{\defOperator{#1}{#2}{H}{}{(}{)}{\mathcal}}
#+LATEX_HEADER: \newcommandx\Score[2][1=,2=]{\defOperator{#1}{#2}{S}{}{(}{)}{\mathcal}}
**** Operators
#+LATEX_HEADER: \newcommandx\Vois[2][1=,2=]{\defOperator{#1}{#2}{V}{}{(}{)}{\mathcal}}
#+LATEX_HEADER: \newcommandx\IF[2][1=,2=]{\defOperator{#1}{#2}{IF}{}{(}{)}{\mathcal}}
#+LATEX_HEADER: \newcommandx\Ind[1][1=]{\defOperator{}{#1}{1}{}{(}{)}{\mathds}}
#+LATEX_HEADER: \newcommandx\Max[2][1=,2=]{\defUOperator{#1}{#2}{(}{)}{min}}
#+LATEX_HEADER: \newcommandx\Min[2][1=,2=]{\defUOperator{#1}{#2}{(}{)}{max}}
#+LATEX_HEADER: \newcommandx\argMax[2][1=,2=]{\defUOperator{#1}{#2}{(}{)}{argmax}}
#+LATEX_HEADER: \newcommandx\argMin[2][1=,2=]{\defUOperator{#1}{#2}{(}{)}{argmin}}
#+LATEX_HEADER: \newcommandx\cvD[2][1=D,2=n \rightarrow \infty]{\xrightarrow[#2]{#1}}
#+LATEX_HEADER: \newcommandx\Hypothesis[2][1=,2=]{
#+LATEX_HEADER:         \ifthenelse{\isempty{#1}}{
#+LATEX_HEADER:         \mathcal{H}
#+LATEX_HEADER:         }{
#+LATEX_HEADER: 	\ifthenelse{\isempty{#2}}{
#+LATEX_HEADER: 		\mathcal{H}_{#1}
#+LATEX_HEADER: 	}{
#+LATEX_HEADER: 	\mathcal{H}^{(#2)}_{#1}
#+LATEX_HEADER:         }
#+LATEX_HEADER:         }
#+LATEX_HEADER: }
#+LATEX_HEADER: \newcommandx\dpartial[4][1=,2=,3=,4=\partial]{
#+LATEX_HEADER: 	\ifthenelse{\isempty{#3}}{
#+LATEX_HEADER: 		\frac{#4 #1}{#4 #2}
#+LATEX_HEADER: 	}{
#+LATEX_HEADER: 	\left.\frac{#4 #1}{#4 #2}\right\rvert_{#3}
#+LATEX_HEADER: }
#+LATEX_HEADER: }
#+LATEX_HEADER: \newcommandx\dTpartial[3][1=,2=,3=]{\dpartial[#1][#2][#3][d]}
#+LATEX_HEADER: \newcommandx\ddpartial[3][1=,2=,3=]{
#+LATEX_HEADER: 	\ifthenelse{\isempty{#3}}{
#+LATEX_HEADER: 		\frac{\partial^{2} #1}{\partial #2^2}
#+LATEX_HEADER: 	}{
#+LATEX_HEADER: 	\frac{\partial^2 #1}{\partial #2\partial #3}
#+LATEX_HEADER: }
#+LATEX_HEADER: } 
**** General math
#+LATEX_HEADER: \newcommand\Real{\mathbb{R}}
#+LATEX_HEADER: \newcommand\Rational{\mathbb{Q}}
#+LATEX_HEADER: \newcommand\Natural{\mathbb{N}}
#+LATEX_HEADER: \newcommand\trans[1]{{#1}^\intercal}%\newcommand\trans[1]{{\vphantom{#1}}^\top{#1}}
#+LATEX_HEADER: \newcommand{\independent}{\mathrel{\text{\scalebox{1.5}{$\perp\mkern-10mu\perp$}}}}
#+LaTeX_HEADER: \newcommand\half{\frac{1}{2}}
#+LaTeX_HEADER: \newcommand\normMax[1]{\left|\left|#1\right|\right|_{max}}
#+LaTeX_HEADER: \newcommand\normTwo[1]{\left|\left|#1\right|\right|_{2}}
#+LATEX_HEADER: \newcommand\Veta{\boldsymbol{\eta}}

** Notations

#+LaTeX_HEADER:\newcommand{\Model}{\mathcal{M}}
#+LaTeX_HEADER:\newcommand{\ModelHat}{\widehat{\mathcal{M}}}

#+LaTeX_HEADER:\newcommand{\param}{\Theta}
#+LaTeX_HEADER:\newcommand{\paramHat}{\widehat{\param}}
#+LaTeX_HEADER:\newcommand{\paramCon}{\widetilde{\param}}

#+LaTeX_HEADER:\newcommand{\Vparam}{\boldsymbol{\param}}
#+LaTeX_HEADER:\newcommand{\VparamT}{\Vparam_0}
#+LaTeX_HEADER:\newcommand{\VparamHat}{\boldsymbol{\paramHat}}
#+LaTeX_HEADER:\newcommand{\VparamCon}{\boldsymbol{\paramCon}}

#+LaTeX_HEADER:\newcommand{\X}{X}
#+LaTeX_HEADER:\newcommand{\x}{x}
#+LaTeX_HEADER:\newcommand{\VX}{\boldsymbol{X}}
#+LaTeX_HEADER:\newcommand{\Vx}{\boldsymbol{x}}

#+LaTeX_HEADER:\newcommand{\Y}{Y}
#+LaTeX_HEADER:\newcommand{\y}{y}
#+LaTeX_HEADER:\newcommand{\VY}{\boldsymbol{Y}}
#+LaTeX_HEADER:\newcommand{\Vy}{\boldsymbol{y}}


